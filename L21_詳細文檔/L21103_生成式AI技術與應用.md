# L21103 生成式AI技術與應用 - 詳細說明

## 一、核心概念與定義

### 1.1 生成式AI定義
生成式AI (Generative AI) 是能夠生成新內容（文本、圖像、音頻、視頻等）的人工智慧技術，與鑑別式AI(Discriminative AI)相對應。

### 1.2 生成式AI vs 鑑別式AI
- **生成式AI**：
  - 學習數據分佈
  - 生成新樣本
  - 應用：內容創作、數據增強
- **鑑別式AI**：
  - 學習類別邊界
  - 分類/預測任務
  - 應用：圖像分類、物件檢測

### 1.3 生成式AI的發展歷程
- **2014年**：GAN (Generative Adversarial Network) 提出
- **2017年**：Transformer架構
- **2018年**：GPT-1、BERT
- **2019年**：GPT-2
- **2020年**：GPT-3、DALL-E
- **2021年**：DALL-E 2、Stable Diffusion
- **2022年**：ChatGPT、Midjourney
- **2023年**：GPT-4、Claude、多模態模型
- **2024年**：GPT-4o、Claude 3.5、更強大的多模態模型

---

## 二、核心技術架構

### 2.1 生成對抗網路(GAN)

#### 2.1.1 GAN基本原理
- **架構組成**：
  - 生成器(Generator)：生成假數據
  - 判別器(Discriminator)：區分真假數據
- **訓練過程**：
  - 對抗性訓練
  - 納什均衡
  - 最小最大博弈
- **損失函數**：
  - 生成器損失
  - 判別器損失
  - 對抗損失

#### 2.1.2 GAN變體
- **DCGAN**：深度卷積GAN
- **WGAN**：Wasserstein GAN
- **StyleGAN**：風格遷移
- **CycleGAN**：無配對圖像轉換
- **Pix2Pix**：配對圖像轉換
- **Progressive GAN**：漸進式生成

#### 2.1.3 GAN的挑戰
- **訓練不穩定**：模式崩塌、梯度消失
- **評估困難**：缺乏客觀指標
- **模式崩塌**：生成樣本多樣性不足

### 2.2 變分自編碼器(VAE)

#### 2.2.1 VAE基本原理
- **架構組成**：
  - 編碼器(Encoder)：將輸入映射到潛在空間
  - 解碼器(Decoder)：從潛在空間生成輸出
- **潛在空間**：
  - 連續的潛在變數
  - 正態分佈假設
- **損失函數**：
  - 重建損失(Reconstruction Loss)
  - KL散度(KL Divergence)

#### 2.2.2 VAE變體
- **β-VAE**：控制潛在空間的緊湊性
- **VQ-VAE**：向量量化VAE
- **Conditional VAE**：條件生成

#### 2.2.3 VAE的優缺點
- **優點**：
  - 訓練穩定
  - 潛在空間可解釋
  - 插值平滑
- **缺點**：
  - 生成質量不如GAN
  - 可能產生模糊圖像

### 2.3 擴散模型(Diffusion Models)

#### 2.3.1 擴散模型原理
- **前向過程**：逐步添加噪聲
- **反向過程**：逐步去噪生成
- **數學基礎**：
  - 馬爾可夫鏈
  - 高斯分佈
  - 變分推斷

#### 2.3.2 擴散模型變體
- **DDPM** (Denoising Diffusion Probabilistic Models)
- **DDIM** (Denoising Diffusion Implicit Models)：加速採樣
- **Latent Diffusion**：在潛在空間中擴散
- **Stable Diffusion**：開源的圖像生成模型

#### 2.3.3 擴散模型的優勢
- **生成質量高**
- **訓練穩定**
- **可控性強**
- **多樣性好**

### 2.4 Transformer-based生成模型

#### 2.4.1 自回歸生成
- **原理**：逐個生成token
- **架構**：解碼器Transformer
- **應用**：文本生成、程式碼生成

#### 2.4.2 大型語言模型(LLM)

**GPT系列**
- **GPT-1** (2018)：
  - 117M參數
  - 無監督預訓練+監督微調
- **GPT-2** (2019)：
  - 1.5B參數
  - 零樣本學習能力
- **GPT-3** (2020)：
  - 175B參數
  - 少樣本學習(Few-shot Learning)
  - In-context Learning
- **GPT-4** (2023)：
  - 多模態能力
  - 更強的推理能力
  - 更好的指令遵循

**其他重要LLM**
- **BERT**：雙向編碼器（主要用於理解）
- **T5**：Text-to-Text框架
- **PaLM**：Google的大規模模型
- **LLaMA**：Meta的開源模型
- **Claude**：Anthropic的對齊模型
- **Gemini**：Google的多模態模型

#### 2.4.3 訓練技術
- **預訓練**：
  - 自監督學習
  - 大規模數據
  - 無標註數據
- **微調**：
  - 監督微調(SFT)
  - 指令微調(Instruction Tuning)
  - 多任務微調
- **對齊技術**：
  - RLHF (Reinforcement Learning from Human Feedback)
  - DPO (Direct Preference Optimization)
  - 人類反饋的重要性

---

## 三、文本生成技術

### 3.1 文本生成任務
- **開放域對話**：自由對話生成
- **文本摘要**：生成式摘要
- **機器翻譯**：神經機器翻譯
- **文本續寫**：根據前文生成後續
- **程式碼生成**：根據描述生成程式碼

### 3.2 Prompt工程
- **Prompt設計原則**：
  - 清晰明確
  - 提供上下文
  - 指定輸出格式
  - 使用範例
- **Prompt技術**：
  - Zero-shot：無範例
  - Few-shot：少量範例
  - Chain-of-Thought：思維鏈
  - Role-playing：角色扮演
- **Prompt優化**：
  - A/B測試
  - 迭代改進
  - 模板設計

### 3.3 文本生成評估
- **自動評估指標**：
  - BLEU：機器翻譯
  - ROUGE：摘要生成
  - METEOR：考慮同義詞
  - BERTScore：語義相似度
- **人工評估**：
  - 流暢性
  - 相關性
  - 創造性
  - 事實準確性

### 3.4 文本生成的挑戰
- **幻覺問題**：生成虛假信息
- **重複生成**：重複相同內容
- **不一致性**：前後矛盾
- **偏見問題**：反映訓練數據偏見
- **安全性**：生成有害內容

---

## 四、圖像生成技術

### 4.1 圖像生成方法
- **GAN-based**：StyleGAN、Progressive GAN
- **VAE-based**：VAE、VQ-VAE
- **Diffusion-based**：Stable Diffusion、DALL-E 2
- **Autoregressive**：PixelRNN、Image GPT

### 4.2 文本到圖像生成
- **DALL-E**：
  - 離散VAE + Transformer
  - 高質量圖像生成
- **DALL-E 2**：
  - CLIP引導
  - 更高解析度
- **Stable Diffusion**：
  - 開源模型
  - 潛在空間擴散
  - 廣泛應用
- **Midjourney**：
  - 藝術風格強
  - 商業化應用

### 4.3 圖像生成評估
- **IS (Inception Score)**：多樣性與質量
- **FID (Fréchet Inception Distance)**：真實性評估
- **LPIPS**：感知相似度
- **人工評估**：美觀性、相關性

### 4.4 圖像生成應用
- **藝術創作**：數字藝術、插畫
- **設計輔助**：產品設計、室內設計
- **內容創作**：社交媒體、廣告
- **數據增強**：訓練數據生成

---

## 五、多模態生成

### 5.1 圖文生成
- **圖像描述生成**：Image Captioning
- **文本到圖像**：Text-to-Image
- **圖像編輯**：根據文本修改圖像

### 5.2 音頻生成
- **語音合成**：TTS (Text-to-Speech)
- **音樂生成**：Music Generation
- **音效生成**：Sound Effect Generation

### 5.3 視頻生成
- **文本到視頻**：Text-to-Video
- **圖像到視頻**：Image-to-Video
- **視頻編輯**：Video Editing

---

## 六、應用領域

### 6.1 內容創作
- **文案生成**：廣告文案、文章寫作
- **創意設計**：圖標、插畫、海報
- **視頻製作**：腳本、配音、特效

### 6.2 程式碼生成
- **程式碼補全**：IDE插件
- **程式碼生成**：根據描述生成程式碼
- **程式碼解釋**：解釋現有程式碼
- **程式碼優化**：重構與優化

### 6.3 數據增強
- **訓練數據生成**：增加數據多樣性
- **少樣本學習**：生成少數類樣本
- **對抗樣本生成**：模型測試

### 6.4 個人化應用
- **個人助手**：對話、任務規劃
- **教育輔助**：個性化學習內容
- **娛樂應用**：遊戲、互動內容

---

## 七、技術挑戰與解決方案

### 7.1 技術挑戰
1. **幻覺問題**：生成虛假或錯誤信息
2. **偏見問題**：反映訓練數據偏見
3. **可控性**：難以精確控制生成內容
4. **評估困難**：缺乏客觀評估指標
5. **計算成本**：大模型訓練與推理成本高
6. **安全性**：可能生成有害內容

### 7.2 解決方案
- **對齊技術**：RLHF、DPO
- **檢索增強**：RAG (Retrieval-Augmented Generation)
- **事實檢查**：外部知識庫驗證
- **安全機制**：內容過濾、安全提示
- **可解釋性**：理解模型決策過程
- **模型壓縮**：量化、蒸餾、剪枝

---

## 八、最新發展趨勢(2024-2025)

### 8.1 模型規模
- **持續增大**：參數規模不斷增加
- **效率優化**：更高效的架構與訓練方法
- **開源趨勢**：更多開源模型

### 8.2 多模態融合
- **統一架構**：處理多種模態
- **跨模態理解**：更好的模態間理解
- **多模態生成**：同時生成多種內容

### 8.3 對齊與安全
- **更好的對齊**：與人類價值觀對齊
- **安全性提升**：減少有害內容生成
- **可解釋性**：理解模型行為

### 8.4 應用擴展
- **企業應用**：更多商業場景
- **邊緣部署**：移動端、IoT設備
- **實時生成**：更快的生成速度

---

## 九、實務應用案例

### 9.1 ChatGPT應用
- **對話助手**：智能問答
- **內容創作**：寫作輔助
- **程式碼助手**：程式設計輔助
- **教育應用**：學習輔助

### 9.2 圖像生成應用
- **Midjourney**：藝術創作
- **Stable Diffusion**：開源圖像生成
- **DALL-E**：商業圖像生成

### 9.3 企業應用
- **客服機器人**：智能客服
- **內容營銷**：自動化內容創作
- **產品設計**：設計輔助

---

## 十、考試重點提醒

### 10.1 必記概念
- 生成式AI與鑑別式AI的區別
- GAN、VAE、擴散模型的基本原理
- Transformer架構在生成任務中的應用
- 大型語言模型的發展歷程

### 10.2 技術比較
- GAN vs VAE vs 擴散模型
- 不同生成模型的優缺點
- 文本生成 vs 圖像生成
- 有條件生成 vs 無條件生成

### 10.3 應用場景判斷
- 能夠根據需求選擇合適的生成模型
- 理解不同生成任務的評估指標
- 掌握Prompt設計原則

### 10.4 實務考量
- 生成質量與計算成本的權衡
- 安全性與可控性
- 偏見與倫理問題
- 模型部署與優化

---

## 十一、參考資源

### 11.1 經典論文
- Generative Adversarial Nets (GAN)
- Auto-Encoding Variational Bayes (VAE)
- Denoising Diffusion Probabilistic Models
- Attention Is All You Need (Transformer)
- Language Models are Few-Shot Learners (GPT-3)

### 11.2 實用工具
- **文本生成**：OpenAI API、Hugging Face Transformers
- **圖像生成**：Stable Diffusion、DALL-E API
- **框架**：PyTorch、TensorFlow、JAX

### 11.3 學習資源
- 線上課程：Coursera、edX
- 技術博客：Towards Data Science、Papers with Code
- 開源項目：GitHub上的生成模型項目

---

**考試日期：2026/05/23**
