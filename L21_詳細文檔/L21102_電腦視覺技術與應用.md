# L21102 電腦視覺技術與應用 - 詳細說明

## 一、核心概念與定義

### 1.1 電腦視覺(CV)定義
電腦視覺(Computer Vision, CV)是讓電腦從圖像或視頻中提取、分析和理解資訊的技術，模擬人類視覺系統的功能。

### 1.2 電腦視覺的發展歷程
- **1960-1970年代**：早期圖像處理
- **1980-1990年代**：特徵提取與模式識別
- **2000-2010年代**：機器學習方法
- **2012年至今**：深度學習革命（AlexNet開啟）

### 1.3 電腦視覺的主要任務
1. **圖像分類**：識別圖像中的主要物體
2. **物件檢測**：定位並識別圖像中的多個物體
3. **語義分割**：為每個像素分配類別標籤
4. **實例分割**：區分同一類別的不同實例
5. **關鍵點檢測**：檢測物體的特徵點
6. **光流估計**：估計像素的運動

---

## 二、核心技術詳解

### 2.1 圖像預處理技術

#### 2.1.1 圖像增強(Image Enhancement)
- **對比度調整**：直方圖均衡化、CLAHE
- **亮度調整**：Gamma校正、亮度正規化
- **色彩調整**：色彩平衡、飽和度調整
- **去霧處理**：提高圖像清晰度

#### 2.1.2 降噪(Denoising)
- **空間域濾波**：
  - 均值濾波
  - 中值濾波
  - 高斯濾波
- **頻域濾波**：傅立葉變換、小波變換
- **深度學習方法**：自編碼器、CNN-based去噪

#### 2.1.3 幾何變換(Geometric Transformation)
- **旋轉**：任意角度旋轉
- **縮放**：放大或縮小
- **平移**：圖像位移
- **翻轉**：水平/垂直翻轉
- **裁剪**：區域提取
- **仿射變換**：保持平行線的變換
- **透視變換**：投影變換

#### 2.1.4 色彩空間轉換
- **RGB**：紅綠藍色彩空間
- **HSV/HSL**：色調、飽和度、明度
- **LAB**：感知均勻的色彩空間
- **灰度轉換**：RGB到灰度的轉換

### 2.2 特徵提取技術

#### 2.2.1 傳統特徵提取方法
- **SIFT (Scale-Invariant Feature Transform)**：
  - 尺度不變特徵
  - 旋轉不變性
  - 應用：圖像匹配、物體識別
- **SURF (Speeded Up Robust Features)**：
  - SIFT的加速版本
  - 計算效率更高
- **HOG (Histogram of Oriented Gradients)**：
  - 梯度方向直方圖
  - 應用：行人檢測
- **LBP (Local Binary Pattern)**：
  - 局部二值模式
  - 紋理特徵提取

#### 2.2.2 深度學習特徵提取
- **CNN特徵**：
  - 卷積層自動學習特徵
  - 多層次特徵表示
  - 端到端學習

### 2.3 卷積神經網路(CNN)架構

#### 2.3.1 CNN基本組件
- **卷積層(Convolutional Layer)**：
  - 卷積操作
  - 特徵映射
  - 參數共享
- **池化層(Pooling Layer)**：
  - 最大池化(Max Pooling)
  - 平均池化(Average Pooling)
  - 降低維度、防止過擬合
- **全連接層(Fully Connected Layer)**：
  - 特徵整合
  - 分類輸出
- **激活函數**：
  - ReLU、Leaky ReLU
  - Sigmoid、Tanh
  - Swish、GELU

#### 2.3.2 經典CNN架構

**LeNet (1998)**
- 第一個成功的CNN架構
- 手寫數字識別

**AlexNet (2012)**
- ImageNet競賽冠軍
- 深度學習復興的標誌
- 使用ReLU、Dropout、數據增強

**VGG (2014)**
- 深層網路（16-19層）
- 小卷積核（3×3）
- 簡單有效的架構

**ResNet (2015)**
- 殘差連接(Residual Connection)
- 解決梯度消失問題
- 可訓練極深網路（100+層）

**Inception系列**
- Inception v1：多尺度卷積
- Inception v2/v3：優化與正規化
- Inception v4：結合ResNet

**DenseNet (2017)**
- 密集連接
- 特徵重用
- 參數效率高

**EfficientNet (2019)**
- 複合縮放策略
- 效率與準確率平衡

### 2.4 物件檢測技術

#### 2.4.1 兩階段檢測器(Two-Stage Detectors)
- **R-CNN (Region-based CNN)**：
  - 候選區域生成
  - CNN特徵提取
  - 分類與回歸
- **Fast R-CNN**：
  - 共享卷積計算
  - ROI Pooling
- **Faster R-CNN**：
  - RPN (Region Proposal Network)
  - 端到端訓練
- **Mask R-CNN**：
  - 實例分割
  - ROI Align

#### 2.4.2 單階段檢測器(One-Stage Detectors)
- **YOLO (You Only Look Once)**：
  - YOLO v1：單次前向傳播
  - YOLO v2：多尺度訓練
  - YOLO v3：多尺度預測
  - YOLO v4：優化策略
  - YOLO v5/v6/v7/v8：持續改進
- **SSD (Single Shot Detector)**：
  - 多尺度特徵圖
  - 默認框(Default Boxes)
- **RetinaNet**：
  - Focal Loss
  - 解決類別不平衡

### 2.5 圖像分割技術

#### 2.5.1 語義分割(Semantic Segmentation)
- **FCN (Fully Convolutional Networks)**：
  - 全卷積架構
  - 上採樣恢復解析度
- **U-Net**：
  - 編碼器-解碼器架構
  - 跳躍連接(Skip Connection)
  - 醫學影像應用
- **DeepLab系列**：
  - Atrous Convolution（空洞卷積）
  - ASPP (Atrous Spatial Pyramid Pooling)
  - CRF後處理

#### 2.5.2 實例分割(Instance Segmentation)
- **Mask R-CNN**：檢測+分割
- **YOLACT**：實時實例分割
- **SOLO**：直接預測實例掩碼

### 2.6 其他重要技術

#### 2.6.1 人臉識別
- **傳統方法**：Eigenfaces、Fisherfaces
- **深度學習**：
  - FaceNet：三元組損失
  - ArcFace：角度邊際損失
  - 人臉關鍵點檢測

#### 2.6.2 OCR (光學字符識別)
- **傳統方法**：模板匹配
- **深度學習**：
  - CRNN：CNN+RNN
  - Attention-based OCR
  - Transformer-based OCR

#### 2.6.3 圖像生成
- **GAN**：生成對抗網路
- **VAE**：變分自編碼器
- **Diffusion Models**：擴散模型

---

## 三、主要應用領域

### 3.1 自動駕駛
- **任務**：
  - 車道檢測
  - 車輛/行人檢測
  - 交通標誌識別
  - 3D物體檢測
- **技術**：多感測器融合、實時檢測

### 3.2 醫療影像診斷
- **應用**：
  - X光片分析
  - CT/MRI影像分析
  - 病理切片分析
  - 皮膚病診斷
- **挑戰**：數據隱私、可解釋性

### 3.3 工業品質檢測
- **應用**：
  - 產品缺陷檢測
  - 表面質量檢查
  - 組裝驗證
- **技術**：異常檢測、精確定位

### 3.4 零售業應用
- **應用**：
  - 商品識別
  - 庫存管理
  - 顧客行為分析
  - 無人商店

### 3.5 安防監控
- **應用**：
  - 人臉識別
  - 行為分析
  - 異常檢測
  - 人群計數

### 3.6 農業應用
- **應用**：
  - 作物監測
  - 病蟲害識別
  - 收穫預測
  - 無人機巡檢

---

## 四、數據處理與增強

### 4.1 數據標註
- **標註類型**：
  - 分類標籤
  - 邊界框(Bounding Box)
  - 分割掩碼(Mask)
  - 關鍵點(Keypoints)
- **標註工具**：LabelImg、CVAT、Labelbox

### 4.2 數據增強策略
- **幾何變換**：旋轉、翻轉、裁剪、縮放
- **色彩變換**：亮度、對比度、飽和度調整
- **噪聲添加**：高斯噪聲、椒鹽噪聲
- **混合方法**：MixUp、CutMix、Mosaic
- **自動增強**：AutoAugment、RandAugment

### 4.3 數據不平衡處理
- **採樣策略**：
  - 過採樣(Over-sampling)
  - 欠採樣(Under-sampling)
  - SMOTE
- **損失函數**：Focal Loss、Class-Balanced Loss
- **數據合成**：GAN生成少數類樣本

---

## 五、模型訓練與優化

### 5.1 訓練策略
- **遷移學習**：
  - 預訓練模型微調
  - 特徵提取
  - 凍結層策略
- **學習率調度**：
  - Step Decay
  - Cosine Annealing
  - Warm-up策略
- **正規化技術**：
  - Dropout
  - Batch Normalization
  - Layer Normalization
  - Group Normalization

### 5.2 模型優化
- **模型壓縮**：
  - 量化(Quantization)
  - 剪枝(Pruning)
  - 知識蒸餾(Knowledge Distillation)
- **架構搜索**：NAS (Neural Architecture Search)
- **高效架構**：MobileNet、ShuffleNet、EfficientNet

### 5.3 損失函數
- **分類任務**：交叉熵損失
- **檢測任務**：
  - 分類損失
  - 定位損失(L1/L2)
  - Focal Loss
- **分割任務**：
  - 交叉熵損失
  - Dice Loss
  - IoU Loss

---

## 六、評估指標

### 6.1 分類任務指標
- **準確率(Accuracy)**
- **Top-1/Top-5準確率**
- **混淆矩陣**

### 6.2 檢測任務指標
- **mAP (mean Average Precision)**：
  - AP計算
  - IoU閾值
  - 不同類別的mAP
- **IoU (Intersection over Union)**
- **FPS (Frames Per Second)**：推理速度

### 6.3 分割任務指標
- **Pixel Accuracy**
- **Mean IoU (mIoU)**
- **Dice Coefficient**
- **F1-Score**

---

## 七、最新發展趨勢(2024-2025)

### 7.1 Vision Transformer (ViT)
- **Transformer在視覺的應用**
- **Patch-based處理**
- **自注意力機制**
- **與CNN的結合**：ConvNeXt、Swin Transformer

### 7.2 自監督學習
- **對比學習**：SimCLR、MoCo
- **掩碼自編碼器**：MAE (Masked Autoencoder)
- **無標註數據預訓練**

### 7.3 多模態融合
- **CLIP**：圖像-文本對比學習
- **DALL-E**：文本到圖像生成
- **視覺-語言模型**

### 7.4 實時推理優化
- **模型量化**
- **TensorRT優化**
- **邊緣計算部署**
- **移動端推理**

---

## 八、實務應用案例

### 8.1 醫療影像診斷系統
- **架構**：
  - 數據預處理
  - 病灶檢測模型
  - 分類模型
  - 可解釋性模組
- **挑戰**：
  - 數據隱私
  - 模型可解釋性
  - 臨床驗證

### 8.2 智能監控系統
- **功能**：
  - 實時人臉識別
  - 行為分析
  - 異常檢測
  - 多攝像頭融合
- **技術**：
  - 實時推理
  - 多目標追蹤
  - 場景理解

### 8.3 自動駕駛視覺系統
- **任務**：
  - 多物體檢測
  - 3D物體檢測
  - 語義分割
  - 深度估計
- **要求**：
  - 實時性
  - 高精度
  - 魯棒性

---

## 九、技術挑戰與解決方案

### 9.1 常見挑戰
1. **光照變化**：不同光照條件下的性能
2. **視角變化**：不同角度的物體識別
3. **遮擋問題**：部分遮擋的物體檢測
4. **尺度變化**：不同大小的物體
5. **類內變化**：同一類別的不同外觀
6. **類間相似性**：不同類別的相似外觀

### 9.2 解決方案
- **數據增強**：增加訓練數據多樣性
- **多尺度處理**：處理不同尺度的物體
- **注意力機制**：關注重要區域
- **對抗訓練**：提高模型魯棒性
- **領域適應**：適應不同環境

---

## 十、考試重點提醒

### 10.1 必記概念
- CNN的基本組件與作用
- 物件檢測與圖像分割的區別
- 兩階段與單階段檢測器的優缺點
- 各種評估指標的計算方法

### 10.2 技術比較
- CNN vs Transformer
- YOLO vs R-CNN系列
- 語義分割 vs 實例分割
- 傳統方法 vs 深度學習方法

### 10.3 應用場景判斷
- 能夠根據應用需求選擇合適的技術
- 理解不同任務的評估指標
- 掌握數據增強策略

### 10.4 實務考量
- 實時性 vs 準確率的權衡
- 計算資源與模型選擇
- 數據標註成本
- 模型部署與優化

---

## 十一、參考資源

### 11.1 經典論文
- ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)
- Rich feature hierarchies for accurate object detection (R-CNN)
- You Only Look Once (YOLO)
- U-Net: Convolutional Networks for Biomedical Image Segmentation

### 11.2 實用工具
- **Python庫**：OpenCV、PIL/Pillow、scikit-image
- **深度學習框架**：PyTorch、TensorFlow、Keras
- **預訓練模型**：Torchvision、TensorFlow Hub

### 11.3 數據集
- **分類**：ImageNet、CIFAR-10/100
- **檢測**：COCO、Pascal VOC
- **分割**：Cityscapes、ADE20K
- **人臉**：LFW、CelebA

---

**考試日期：2026/05/23**
