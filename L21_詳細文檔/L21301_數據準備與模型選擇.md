# L21301 數據準備與模型選擇 - 詳細說明

## 一、核心概念與定義

### 1.1 數據準備定義
數據準備是機器學習專案中的關鍵步驟，包括數據收集、清理、轉換和特徵工程，目的是將原始數據轉換為適合模型訓練的格式。

### 1.2 模型選擇定義
模型選擇是根據問題類型、數據特徵和業務需求，選擇最適合的機器學習模型和演算法的過程。

### 1.3 重要性
- **數據品質決定模型性能**：高品質數據是成功模型的基礎
- **合適的模型提升效果**：選擇合適的模型能顯著提升性能
- **節省時間和資源**：良好的準備和選擇能提高效率

---

## 二、數據準備

### 2.1 數據收集

#### 2.1.1 數據來源識別
- **內部數據源**：
  - 業務系統數據
  - 資料庫數據
  - 日誌數據
  - 歷史數據
- **外部數據源**：
  - 公開數據集
  - 第三方數據
  - API數據
  - 爬蟲數據
- **數據獲取方式**：
  - 直接查詢
  - 數據導出
  - API調用
  - 數據採購

#### 2.1.2 數據獲取策略
- **數據需求分析**：
  - 數據類型需求
  - 數據量需求
  - 數據品質需求
  - 數據時效性需求
- **獲取計畫**：
  - 獲取時間表
  - 獲取方法
  - 獲取成本
  - 獲取風險

#### 2.1.3 數據品質標準
- **完整性**：數據是否完整
- **準確性**：數據是否準確
- **一致性**：數據格式是否一致
- **時效性**：數據是否及時
- **相關性**：數據是否相關

### 2.2 數據清理

#### 2.2.1 缺失值處理
- **缺失值類型**：
  - **MCAR (Missing Completely At Random)**：完全隨機缺失
  - **MAR (Missing At Random)**：隨機缺失
  - **MNAR (Missing Not At Random)**：非隨機缺失
- **處理策略**：
  - **刪除**：
    - 刪除整行（缺失值少）
    - 刪除整列（缺失值多且不重要）
  - **填補**：
    - 統計值填補：平均值、中位數、眾數
    - 回歸填補：使用其他變數預測
    - 插值填補：時間序列插值
    - KNN填補：使用相似樣本
  - **標記**：保留缺失信息作為特徵

#### 2.2.2 異常值檢測與處理
- **檢測方法**：
  - **統計方法**：
    - Z-score：|z| > 3為異常
    - IQR方法：超出Q3+1.5×IQR或Q1-1.5×IQR
  - **視覺化方法**：
    - 箱線圖
    - 散點圖
  - **機器學習方法**：
    - 孤立森林(Isolation Forest)
    - DBSCAN
    - 一類SVM
- **處理策略**：
  - **刪除**：明顯錯誤的異常值
  - **修正**：可修正的異常值
  - **轉換**：對數轉換、Box-Cox轉換
  - **保留**：可能是真實的極端值

#### 2.2.3 數據一致性檢查
- **格式一致性**：
  - 日期格式統一
  - 數值格式統一
  - 文字格式統一
- **編碼一致性**：
  - 字符編碼統一（UTF-8）
  - 類別編碼統一
- **單位一致性**：
  - 度量單位統一
  - 貨幣單位統一
- **重複數據識別與移除**：
  - 完全重複
  - 近似重複
  - 業務邏輯重複

#### 2.2.4 數據轉換
- **數據類型轉換**：
  - 字符串轉數值
  - 數值轉類別
  - 日期轉換
- **數據正規化**：
  - Min-Max正規化：[0,1]區間
  - Z-score標準化：均值0，標準差1
- **數據標準化**：
  - 單位標準化
  - 格式標準化

### 2.3 數據預處理

#### 2.3.1 數據標準化與正規化
- **標準化(Standardization)**：
  - Z-score標準化
  - 適用於：數據分佈近似常態
  - 公式：z = (x - μ) / σ
- **正規化(Normalization)**：
  - Min-Max正規化
  - 適用於：需要固定範圍
  - 公式：x' = (x - min) / (max - min)
- **選擇原則**：
  - 標準化：數據分佈未知或非均勻
  - 正規化：需要固定範圍或圖像數據

#### 2.3.2 特徵工程
- **特徵創建**：
  - 領域知識特徵
  - 交互特徵：特徵組合
  - 多項式特徵：特徵的冪次
  - 時間特徵：時間相關特徵
- **特徵轉換**：
  - 對數轉換：處理偏態分佈
  - 平方根轉換：處理計數數據
  - Box-Cox轉換：一般化轉換
- **特徵選擇**：
  - **Filter方法**：
    - 相關性分析
    - 卡方檢定
    - 互信息
  - **Wrapper方法**：
    - 前向選擇
    - 後向消除
    - 遞歸特徵消除
  - **Embedded方法**：
    - L1正規化(Lasso)
    - 樹模型特徵重要性
    - 正規化回歸

#### 2.3.3 數據分割
- **訓練集(Training Set)**：
  - 用途：模型訓練
  - 比例：通常60-80%
- **驗證集(Validation Set)**：
  - 用途：模型選擇和超參數調優
  - 比例：通常10-20%
- **測試集(Test Set)**：
  - 用途：最終性能評估
  - 比例：通常10-20%
- **分割方法**：
  - 隨機分割
  - 分層分割：保持類別比例
  - 時間分割：時間序列數據
  - K折交叉驗證

#### 2.3.4 數據增強技術
- **圖像增強**：
  - 旋轉、翻轉、裁剪
  - 色彩調整
  - 噪聲添加
- **文本增強**：
  - 同義詞替換
  - 回譯
  - 文本生成
- **數值數據增強**：
  - SMOTE：合成少數類樣本
  - 數據插值
  - 噪聲添加

### 2.4 類別不平衡處理
- **問題**：某些類別樣本遠多於其他類別
- **處理方法**：
  - **過採樣(Over-sampling)**：
    - 隨機過採樣
    - SMOTE
    - ADASYN
  - **欠採樣(Under-sampling)**：
    - 隨機欠採樣
    - Tomek Links
    - Edited Nearest Neighbours
  - **組合方法**：
    - SMOTE + Tomek
    - SMOTE + ENN
  - **演算法層面**：
    - 類別權重
    - 成本敏感學習
    - Focal Loss

---

## 三、模型選擇

### 3.1 問題類型判斷

#### 3.1.1 監督學習 vs 無監督學習
- **監督學習**：
  - 有標籤數據
  - 任務：分類、回歸
  - 方法：線性回歸、邏輯回歸、決策樹、SVM、神經網路
- **無監督學習**：
  - 無標籤數據
  - 任務：聚類、降維、異常檢測
  - 方法：K-means、DBSCAN、PCA、t-SNE

#### 3.1.2 分類 vs 回歸 vs 聚類
- **分類(Classification)**：
  - 目標：預測類別標籤
  - 輸出：離散值
  - 評估：準確率、精確率、召回率、F1
- **回歸(Regression)**：
  - 目標：預測數值
  - 輸出：連續值
  - 評估：MSE、MAE、R²
- **聚類(Clustering)**：
  - 目標：發現數據結構
  - 輸出：簇標籤
  - 評估：輪廓係數、DB指數

#### 3.1.3 序列問題 vs 靜態問題
- **序列問題**：
  - 時間序列預測
  - 自然語言處理
  - 方法：RNN、LSTM、GRU、Transformer
- **靜態問題**：
  - 圖像分類
  - 表格數據
  - 方法：傳統ML、CNN、樹模型

### 3.2 模型評估指標

#### 3.2.1 分類任務指標
- **準確率(Accuracy)**：
  - 公式：(TP + TN) / (TP + TN + FP + FN)
  - 適用：類別平衡
- **精確率(Precision)**：
  - 公式：TP / (TP + FP)
  - 意義：預測為正例中真正例的比例
- **召回率(Recall)**：
  - 公式：TP / (TP + FN)
  - 意義：真正例中被預測出的比例
- **F1-Score**：
  - 公式：2 × (Precision × Recall) / (Precision + Recall)
  - 意義：精確率和召回率的調和平均
- **ROC-AUC**：
  - 意義：ROC曲線下面積
  - 範圍：[0, 1]
  - 解釋：模型區分能力
- **混淆矩陣(Confusion Matrix)**：
  - TP、TN、FP、FN
  - 視覺化分類結果

#### 3.2.2 回歸任務指標
- **MSE (Mean Squared Error)**：
  - 公式：Σ(y - ŷ)² / n
  - 特點：對大誤差懲罰重
- **MAE (Mean Absolute Error)**：
  - 公式：Σ|y - ŷ| / n
  - 特點：對異常值不敏感
- **RMSE (Root Mean Squared Error)**：
  - 公式：√MSE
  - 特點：與目標變數同單位
- **R² (決定係數)**：
  - 公式：1 - SS_res / SS_tot
  - 範圍：(-∞, 1]
  - 意義：解釋變異比例

#### 3.2.3 其他指標
- **對數損失(Log Loss)**：分類任務
- **平均絕對百分比誤差(MAPE)**：回歸任務
- **Spearman相關係數**：排序相關性

### 3.3 模型選擇策略

#### 3.3.1 基準模型建立
- **目的**：建立性能基準
- **方法**：
  - 簡單模型：平均值、中位數
  - 線性模型：線性回歸、邏輯回歸
  - 規則模型：if-else規則
- **意義**：後續模型必須優於基準

#### 3.3.2 模型比較方法
- **單一指標比較**：選擇一個主要指標
- **多指標比較**：綜合多個指標
- **統計檢定**：檢定性能差異是否顯著
- **成本效益分析**：考慮計算成本

#### 3.3.3 交叉驗證(Cross-Validation)
- **K折交叉驗證**：
  - 將數據分為K折
  - 每次用K-1折訓練，1折驗證
  - 重複K次，取平均
- **留一法(LOOCV)**：K = n
- **分層K折**：保持類別比例
- **時間序列交叉驗證**：考慮時間順序

#### 3.3.4 超參數調優
- **網格搜索(Grid Search)**：
  - 窮舉所有組合
  - 計算量大但全面
- **隨機搜索(Random Search)**：
  - 隨機選擇組合
  - 效率更高
- **貝葉斯優化(Bayesian Optimization)**：
  - 基於歷史結果選擇
  - 效率最高
- **自動化工具**：
  - Optuna
  - Hyperopt
  - Scikit-learn GridSearchCV

### 3.4 模型選擇考量因素

#### 3.4.1 數據特徵
- **數據量**：
  - 小數據：簡單模型（線性模型、決策樹）
  - 大數據：複雜模型（深度學習）
- **數據維度**：
  - 低維：傳統ML
  - 高維：降維或深度學習
- **數據類型**：
  - 數值：回歸、分類
  - 類別：分類、聚類
  - 文本：NLP模型
  - 圖像：CNN
  - 序列：RNN、Transformer

#### 3.4.2 性能要求
- **準確率要求**：高準確率需求選擇複雜模型
- **速度要求**：實時需求選擇快速模型
- **可解釋性要求**：需要解釋選擇可解釋模型

#### 3.4.3 資源限制
- **計算資源**：GPU、記憶體限制
- **時間限制**：訓練時間限制
- **成本限制**：雲端成本限制

---

## 四、實務應用

### 4.1 數據準備流程
1. **數據收集**：識別和獲取數據
2. **數據探索**：了解數據特徵
3. **數據清理**：處理缺失值、異常值
4. **特徵工程**：創建和選擇特徵
5. **數據分割**：訓練/驗證/測試集
6. **數據增強**：增加數據多樣性

### 4.2 模型選擇流程
1. **問題定義**：明確問題類型
2. **基準建立**：建立基準模型
3. **候選模型**：選擇候選模型
4. **模型訓練**：訓練候選模型
5. **模型評估**：評估模型性能
6. **模型選擇**：選擇最佳模型
7. **超參數調優**：優化超參數

---

## 五、考試重點提醒

### 5.1 必記概念
- 數據準備的步驟和方法
- 缺失值處理策略
- 異常值檢測方法
- 模型評估指標的計算和解釋
- 交叉驗證的原理

### 5.2 實務應用
- 能夠進行數據清理
- 能夠進行特徵工程
- 能夠選擇合適的模型
- 能夠評估模型性能

### 5.3 計算能力
- 能夠計算各種評估指標
- 能夠進行交叉驗證
- 能夠進行數據分割

---

## 六、參考資源

### 6.1 工具與庫
- **Python**：
  - Pandas：數據處理
  - NumPy：數值計算
  - Scikit-learn：機器學習
  - XGBoost、LightGBM：梯度提升

### 6.2 學習資源
- 機器學習教科書
- 線上課程
- 實務案例

---

**考試日期：2026/05/23**
