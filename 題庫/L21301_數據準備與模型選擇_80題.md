# 數據準備與模型選擇 - 80題單選題題庫

基於 L21301_數據準備與模型選擇.md

考試日期：2026/05/23

---

## 第一部分：核心概念與定義 (10題)

### 1. 數據準備在機器學習專案中的定義是？
A. 只包括數據收集  
B. 將原始數據轉換為適合模型訓練格式的過程  
C. 只包括數據清理  
D. 只包括特徵工程

**正確答案：B**  
**解析：** 數據準備是機器學習專案中的關鍵步驟，包括數據收集、清理、轉換和特徵工程，目的是將原始數據轉換為適合模型訓練的格式。

### 2. 模型選擇的定義是？
A. 隨機選擇模型  
B. 根據問題類型、數據特徵和業務需求選擇最適合的模型  
C. 總是選擇最新的模型  
D. 總是選擇最複雜的模型

**正確答案：B**  
**解析：** 模型選擇是根據問題類型、數據特徵和業務需求，選擇最適合的機器學習模型和演算法的過程。

### 3. 高品質數據對模型的影響主要體現在？
A. 降低模型性能  
B. 決定模型性能的基礎  
C. 與模型性能無關  
D. 增加訓練時間

**正確答案：B**  
**解析：** 數據品質決定模型性能，高品質數據是成功模型的基礎。

### 4. 數據準備的重要性不包括？
A. 提升模型效果  
B. 節省時間和資源  
C. 增加專案複雜度  
D. 確保數據品質

**正確答案：C**  
**解析：** 數據準備的重要性包括提升模型效果、節省時間資源和確保數據品質，而不是增加複雜度。

### 5. 數據準備的步驟通常不包括？
A. 數據收集  
B. 模型部署  
C. 數據清理  
D. 特徵工程

**正確答案：B**  
**解析：** 模型部署屬於後續階段，數據準備包括收集、清理、轉換和特徵工程。

### 6. 內部數據源不包括？
A. 業務系統數據  
B. 公開數據集  
C. 資料庫數據  
D. 日誌數據

**正確答案：B**  
**解析：** 公開數據集屬於外部數據源。

### 7. 外部數據源不包括？
A. 爬蟲數據  
B. 第三方數據  
C. 企業內部日誌  
D. API數據

**正確答案：C**  
**解析：** 企業內部日誌屬於內部數據源。

### 8. 數據品質標準中的「完整性」是指？
A. 數據格式一致  
B. 數據是否缺失  
C. 數據是否及時  
D. 數據是否準確

**正確答案：B**  
**解析：** 完整性是指數據是否存在缺失。

### 9. 數據品質標準中的「一致性」是指？
A. 數據是否準確  
B. 數據是否及時  
C. 數據格式是否統一  
D. 數據是否相關

**正確答案：C**  
**解析：** 一致性是指數據格式、編碼和單位是否統一。

### 10. 數據獲取策略中的數據需求分析不包括？
A. 數據類型需求  
B. 數據量需求  
C. 模型參數需求  
D. 數據品質需求

**正確答案：C**  
**解析：** 模型參數需求屬於建模階段，不屬於數據獲取階段的需求分析。

---

## 第二部分：數據清理與預處理 (15題)

### 11. 缺失值類型MCAR是指？
A. 非隨機缺失  
B. 隨機缺失  
C. 完全隨機缺失  
D. 部分隨機缺失

**正確答案：C**  
**解析：** MCAR (Missing Completely At Random) 是指完全隨機缺失。

### 12. 缺失值處理策略中，刪除整行適用於？
A. 缺失值很多  
B. 缺失值很少  
C. 缺失值很重要  
D. 數據量很少

**正確答案：B**  
**解析：** 當缺失值很少時，可以考慮刪除整行。

### 13. 缺失值填補方法不包括？
A. 平均值填補  
B. 隨機填補  
C. 刪除法  
D. KNN填補

**正確答案：C**  
**解析：** 刪除法是處理策略的一種，但不屬於「填補」方法。

### 14. 異常值檢測的統計方法Z-score通常以多少為閾值？
A. |z| > 1  
B. |z| > 2  
C. |z| > 3  
D. |z| > 5

**正確答案：C**  
**解析：** 通常將 Z-score 絕對值大於 3 的數據點視為異常值。

### 15. 箱線圖(Box Plot)利用什麼來檢測異常值？
A. 平均值  
B. 四分位距(IQR)  
C. 標準差  
D. 變異數

**正確答案：B**  
**解析：** 箱線圖利用 IQR (四分位距) 來定義上下界，超出範圍的為異常值。

### 16. 下列哪種方法屬於機器學習異常檢測方法？
A. Z-score  
B. IQR  
C. 孤立森林(Isolation Forest)  
D. 散點圖

**正確答案：C**  
**解析：** 孤立森林是基於機器學習的異常檢測算法。

### 17. 數據一致性檢查不包括？
A. 日期格式統一  
B. 字符編碼統一  
C. 模型準確率檢查  
D. 度量單位統一

**正確答案：C**  
**解析：** 模型準確率檢查屬於模型評估，不屬於數據一致性檢查。

### 18. min-max正規化的結果範圍是？
A. [-1, 1]  
B. [0, 1]  
C. (-∞, +∞)  
D. [0, 100]

**正確答案：B**  
**解析：** Min-Max正規化將數據縮放到 [0, 1] 區間。

### 19. Z-score標準化後的數據特徵是？
A. 均值為0，標準差為1  
B. 均值為1，標準差為0  
C. 範圍在[0, 1]  
D. 範圍在[-1, 1]

**正確答案：A**  
**解析：** Z-score標準化後的數據均值為0，標準差為1。

### 20. 什麼情況下優先選擇標準化(Standardization)？
A. 需要固定範圍[0, 1]  
B. 處理圖像數據  
C. 數據分佈未知或非均勻  
D. 數據已經是常態分佈

**正確答案：C**  
**解析：** 當數據分佈未知或非均勻，或存在離群值時，通常優先選擇標準化。

### 21. 特徵選擇的Filter方法是基於？
A. 模型性能  
B. 統計指標  
C. 隨機選擇  
D. 遞歸消除

**正確答案：B**  
**解析：** Filter方法基於統計指標（如相關性、卡方檢定）來選擇特徵，獨立於模型。

### 22. 特徵選擇的Wrapper方法特點是？
A. 计算量小  
B. 獨立於模型  
C. 使用模型評估特徵子集  
D. 只能用於線性模型

**正確答案：C**  
**解析：** Wrapper方法使用特定的機器學習模型來評估特徵子集的性能，計算量較大。

### 23. 處理偏態分佈數據常用的特徵轉換方法是？
A. 平方轉換  
B. 對數轉換  
C. 線性轉換  
D. 刪除數據

**正確答案：B**  
**解析：** 對數轉換常用於將右偏分佈的數據轉換為接近常態分佈。

### 24. 驗證集(Validation Set)的主要用途是？
A. 模型訓練  
B. 最終性能評估  
C. 模型選擇和超參數調優  
D. 數據清理

**正確答案：C**  
**解析：** 驗證集用於在訓練過程中進行模型選擇和超參數調優。

### 25. 處理類別不平衡的SMOTE方法屬於？
A. 欠採樣  
B. 過採樣  
C. 模型加權  
D. 數據清理

**正確答案：B**  
**解析：** SMOTE (Synthetic Minority Over-sampling Technique) 是一種合成少數類樣本的過採樣方法。

---

## 第三部分：模型選擇基礎 (15題)

### 26. 監督學習與無監督學習的主要區別是？
A. 數據量大小  
B. 是否有標籤數據  
C. 計算速度  
D. 模型複雜度

**正確答案：B**  
**解析：** 主要區別在於監督學習使用有標籤數據，而無監督學習使用無標籤數據。

### 27. 下列哪項屬於監督學習任務？
A. K-means聚類  
B. 降維  
C. 房價預測(回歸)  
D. 異常檢測

**正確答案：C**  
**解析：** 房價預測屬於回歸任務，是監督學習的一種。

### 28. 下列哪項屬於無監督學習任務？
A. 圖像分類  
B. 情感分析  
C. 客戶分群(聚類)  
D. 垃圾郵件檢測

**正確答案：C**  
**解析：** 客戶分群通常使用聚類算法，屬於無監督學習。

### 29. 分類任務的輸出通常是？
A. 連續數值  
B. 離散類別標籤  
C. 圖像  
D. 文本

**正確答案：B**  
**解析：** 分類任務的目標是預測離散的類別標籤。

### 30. 回歸任務的輸出通常是？
A. 離散類別  
B. 連續數值  
C. 二元值  
D. 排名

**正確答案：B**  
**解析：** 回歸任務的目標是預測連續的數值。

### 31. 適合處理時間序列問題的模型是？
A. 線性回歸  
B. K-means  
C. LSTM  
D. PCA

**正確答案：C**  
**解析：** LSTM (Long Short-Term Memory) 是一種RNN，特別適合處理時間序列數據。

### 32. 適合處理圖像分類問題的模型是？
A. RNN  
B. CNN  
C. 線性回歸  
D. 決策樹

**正確答案：B**  
**解析：** CNN (卷積神經網絡) 是處理圖像數據的首選模型。

### 33. 分類任務中，準確率(Accuracy)公式是？
A. TP / (TP + FP)  
B. (TP + TN) / 總樣本數  
C. TP / (TP + FN)  
D. 2PR / (P + R)

**正確答案：B**  
**解析：** 準確率是正確預測的樣本數 (TP + TN) 除以總樣本數。

### 34. 精確率(Precision)關注的是？
A. 預測為正例中有多少是真正的正例  
B. 所有正例中有多少被預測出來  
C. 預測正確的比例  
D. 錯誤預測的比例

**正確答案：A**  
**解析：** 精確率衡量的是預測為正例的樣本中，實際為正例的比例。

### 35. 召回率(Recall)關注的是？
A. 預測為正例的準確性  
B. 實際正例中有多少被預測出來  
C. 整體準確率  
D. 負例的預測準確率

**正確答案：B**  
**解析：** 召回率衡量的是實際為正例的樣本中，被正確預測為正例的比例。

### 36. F1-Score是哪兩個指標的調和平均？
A. 準確率和召回率  
B. 精確率和準確率  
C. 精確率和召回率  
D. TPR和FPR

**正確答案：C**  
**解析：** F1-Score 是精確率 (Precision) 和召回率 (Recall) 的調和平均。

### 37. ROC-AUC指標的範圍是？
A. [-1, 1]  
B. [0, 1]  
C. [0, 100]  
D. (-∞, +∞)

**正確答案：B**  
**解析：** ROC-AUC 的值域在 0 到 1 之間，0.5 表示隨機猜測，1 表示完美分類。

### 38. 回歸任務中，MSE是指？
A. 平均絕對誤差  
B. 均方誤差  
C. 均方根誤差  
D. 決定係數

**正確答案：B**  
**解析：** MSE (Mean Squared Error) 是均方誤差。

### 39. 對異常值不敏感的回歸評估指標是？
A. MSE  
B. RMSE  
C. MAE  
D. R^2

**正確答案：C**  
**解析：** MAE (Mean Absolute Error) 使用絕對值，相比平方誤差(MSE)，對異常值較不敏感。

### 40. R² (決定係數) 的最大值是？
A. 0  
B. 1  
C. 100  
D. 無窮大

**正確答案：B**  
**解析：** R² 的最大值是 1，表示模型完美擬合數據。

---

## 第四部分：模型選擇策略與實務 (15題)

### 41. 建立基準模型(Baseline)的目的是？
A. 作為最終模型  
B. 建立性能比較的基準  
C. 節省計算資源  
D. 處理缺失值

**正確答案：B**  
**解析：** 基準模型用於設立一個基本的性能標準，後續開發的模型必須優於此基準才有價值。

### 42. K折交叉驗證的步驟不包括？
A. 將數據分為K折  
B. 每次用全部數據訓練  
C. 重複K次訓練和驗證  
D. 取K次結果的平均

**正確答案：B**  
**解析：** K折交叉驗證每次使用 K-1 折做訓練，1 折做驗證，而不是用全部數據訓練。

### 43. 留一法(LOOCV)是K折交叉驗證的一種特例，其中K等於？
A. 1  
B. 5  
C. 10  
D. 樣本總數n

**正確答案：D**  
**解析：** 留一法中，每次只留一個樣本做驗證，所以 K 等於樣本總數 n。

### 44. 網格搜索(Grid Search)的特點是？
A. 隨機搜索參數  
B. 窮舉所有參數組合  
C. 基於歷史結果搜索  
D. 速度最快

**正確答案：B**  
**解析：** 網格搜索會窮舉定義好的所有參數組合，計算量大但全面。

### 45. 貝葉斯優化(Bayesian Optimization)的優點是？
A. 容易實現  
B. 不需要定義參數空間  
C. 效率高，基於歷史結果優化  
D. 總是找到全局最優

**正確答案：C**  
**解析：** 貝葉斯優化利用之前的評估結果來指導下一次搜索，通常比網格搜索和隨機搜索效率更高。

### 46. 面對小數據量，宜選擇哪種模型？
A. 深度神經網絡  
B. 複雜的集成模型  
C. 簡單模型(如線性回歸、決策樹)  
D. Transformer

**正確答案：C**  
**解析：** 小數據量容易導致複雜模型過擬合，因此宜選擇簡單模型。

### 47. 面對高維度數據，通常需要進行？
A. 數據增強  
B. 降維處理  
C. 過採樣  
D. 增加數據量

**正確答案：B**  
**解析：** 高維數據會導致維度災難，通常需要進行降維（如PCA）或選擇能處理高維數據的模型。

### 48. 若對模型可解釋性有高要求，應避免選擇？
A. 線性回歸  
B. 決策樹  
C. 深度神經網絡  
D. 邏輯回歸

**正確答案：C**  
**解析：** 深度神經網絡通常被視為黑盒模型，可解釋性較差。

### 49. 若需要實時預測，模型選擇應優先考慮？
A. 模型複雜度  
B. 訓練時間  
C. 推理(Inference)速度  
D. 參數數量

**正確答案：C**  
**解析：** 實時預測對延遲敏感，因此主要考量模型的推理速度。

### 50. 數據增強技術中，圖像數據常用的方法不包括？
A. 旋轉  
B. 裁剪  
C. 同義詞替換  
D. 噪聲添加

**正確答案：C**  
**解析：** 同義詞替換是文本數據增強的方法。

### 51. 關於過擬合(Overfitting)，下列說法正確的是？
A. 訓練集和測試集表現都差  
B. 訓練集表現好，測試集表現差  
C. 訓練集表現差，測試集表現好  
D. 訓練集和測試集表現都好

**正確答案：B**  
**解析：** 過擬合指模型在訓練集上表現很好，但在未見過的測試集上表現差。

### 52. 解決過擬合的方法不包括？
A. 增加數據量  
B. 正則化(Regularization)  
C. 簡化模型  
D. 增加模型複雜度

**正確答案：D**  
**解析：** 增加模型複雜度會加重過擬合，應該簡化模型。

### 53. 關於欠擬合(Underfitting)，下列說法正確的是？
A. 模型太複雜  
B. 訓練集和測試集表現都差  
C. 訓練集表現好，測試集表現差  
D. 需要減少特徵

**正確答案：B**  
**解析：** 欠擬合指模型無法捕捉數據的規律，訓練集和測試集表現都不好。

### 54. 隨機森林屬於哪種模型？
A. 線性模型  
B. 單一決策樹  
C. 集成模型(Bagging)  
D. 聚類模型

**正確答案：C**  
**解析：** 隨機森林是由多棵決策樹組成的集成模型，採用Bagging策略。

### 55. XGBoost屬於哪種模型？
A. Bagging  
B. Boosting  
C. Stacking  
D. Clustering

**正確答案：B**  
**解析：** XGBoost 是一種梯度提升決策樹 (Gradient Boosting) 算法，屬於 Boosting 家族。

---

## 第五部分：進階概念與應用 (25題)

### 56. 文本數據預處理中，Tokenization是指？
A. 去除停用詞  
B. 分詞  
C. 詞幹提取  
D. 向量化

**正確答案：B**  
**解析：** Tokenization 是將文本序列切分為單詞或子詞單位的過程。

### 57. 類別特徵編碼中，One-Hot Encoding適用於？
A. 類別數量非常多  
B. 類別之間有序關係  
C. 類別數量較少且無序  
D. 數值特徵

**正確答案：C**  
**解析：** One-Hot Encoding 會增加維度，適合類別數量較少且無序的情況。

### 58. 類別特徵編碼中，Label Encoding適用於？
A. 類別之間無序關係  
B. 樹模型或類別有序  
C. 線性模型  
D. 神經網絡

**正確答案：B**  
**解析：** Label Encoding 將類別轉為數字，樹模型可以處理這種編碼，或者當類別有序時適用。

### 59. 處理偏斜數據(Skewed Data)時，常用的評估指標是？
A. 準確率  
B. ROC-AUC 或 F1-Score  
C. MSE  
D. R^2

**正確答案：B**  
**解析：** 在類別不平衡（偏斜）數據中，準確率會失效，應使用 AUC 或 F1-Score。

### 60. 關於數據洩露(Data Leakage)，下列說法正確的是？
A. 訓練數據中包含了測試數據的信息  
B. 數據從數據庫中洩露出去  
C. 模型參數洩露  
D. 數據量太少

**正確答案：A**  
**解析：** 數據洩露通常指訓練模型時意外使用了測試集的信息或未來的信息，導致評估結果虛高。

### 61. 特徵工程中的「交互特徵」是指？
A. 單個特徵的變換  
B. 兩個或多個特徵的組合  
C. 刪除特徵  
D. 選擇特徵

**正確答案：B**  
**解析：** 交互特徵是通過組合兩個或多個現有特徵（如相乘、相加）來創建新特徵。

### 62. Lasso回歸(L1正則化)的一個重要特性是？
A. 可以進行特徵選擇(將係數變為0)  
B. 所有係數都會變小但不會為0  
C. 計算速度比Ridge快  
D. 不適合高維數據

**正確答案：A**  
**解析：** L1正則化傾向於產生稀疏解，即將不重要的特徵係數壓縮為0，從而實現特徵選擇。

### 63. Ridge回歸(L2正則化)的主要作用是？
A. 特徵選擇  
B. 防止過擬合(限制係數大小)  
C. 增加模型複雜度  
D. 處理缺失值

**正確答案：B**  
**解析：** L2正則化通過懲罰係數的平方和來限制係數大小，從而減輕過擬合，但通常不會將係數變為0。

### 64. PCA(主成分分析)是一種？
A. 監督學習算法  
B. 線性降維算法  
C. 非線性降維算法  
D. 聚類算法

**正確答案：B**  
**解析：** PCA 是一種常用的線性降維技術，屬於無監督學習。

### 65. t-SNE主要用於？
A. 數據壓縮  
B. 高維數據視覺化  
C. 特徵選擇  
D. 回歸預測

**正確答案：B**  
**解析：** t-SNE 是一種非線性降維算法，特別適合將高維數據降至2D或3D進行視覺化。

### 66. 在時間序列交叉驗證中，為什麼不能使用隨機K折？
A. 數據量太大  
B. 會破壞時間順序，導致數據洩露  
C.計算太慢  
D. 模型不支持

**正確答案：B**  
**解析：** 時間序列數據具有時間依賴性，隨機打亂會導致用未來的數據預測過去（數據洩露）。

### 67. 下列哪個庫是用於自動化超參數優化的？
A. Pandas  
B. NumPy  
C. Optuna  
D. Matplotlib

**正確答案：C**  
**解析：** Optuna 是一個現代化的自動超參數優化框架。

### 68. 混淆矩陣中，FP (False Positive) 代表？
A. 實際為正，預測為正  
B. 實際為負，預測為負  
C. 實際為負，預測為正  
D. 實際為正，預測為負

**正確答案：C**  
**解析：** False Positive (假正例) 指實際為負例，但被模型錯誤預測為正例。

### 69. 均方根誤差(RMSE)與均方誤差(MSE)相比，優點是？
A. 計算更簡單  
B. 量綱(單位)與目標變數一致  
C. 數值更小  
D. 不受異常值影響

**正確答案：B**  
**解析：** RMSE 開了根號，使其單位與原始目標變數一致，更易於解釋。

### 70. 決策樹模型的一個主要優點是？
A. 預測精度最高  
B. 不容易過擬合  
C. 可解釋性強  
D. 適合處理圖像

**正確答案：C**  
**解析：** 決策樹的規則類似人類的決策邏輯，具有很強的可解釋性。

### 71. 集成學習中，Stacking的主要思想是？
A. 並行訓練多個模型取平均  
B. 串行訓練多個模型修正誤差  
C. 使用一個元模型(Meta-model)組合多個基模型的預測  
D. 使用單一模型多次訓練

**正確答案：C**  
**解析：** Stacking 利用一個元模型來學習如何組合多個基模型的預測結果。

### 72. 數據探索(EDA)的目的不包括？
A. 了解數據分佈  
B. 發現異常值  
C. 訓練最終模型  
D. 發現變數間的關係

**正確答案：C**  
**解析：** 數據探索是在建模之前進行的，目的是理解數據，而不是訓練最終模型。

### 73. 相關性分析(Correlation Analysis)主要用於？
A. 檢測異常值  
B. 評估特徵與目標變數的線性關係  
C. 預測結果  
D. 填補缺失值

**正確答案：B**  
**解析：** 相關性分析用於衡量變數之間的線性相關程度，常用於特徵選擇。

### 74. 在處理數值型特徵時，如果數據分佈呈現長尾(Long Tail)，通常採用什麼轉換？
A. 線性轉換  
B. 對數轉換(Log Transform)  
C. 離散化  
D. 歸一化

**正確答案：B**  
**解析：** 對數轉換可以壓縮長尾部分，使數據分佈更接近常態分佈。

### 75. 哪種模型對特徵縮放(Feature Scaling)不敏感？
A. 邏輯回歸  
B. SVM  
C. K-means  
D. 決策樹/隨機森林

**正確答案：D**  
**解析：** 樹模型是用單個特徵進行分裂，不依賴特徵之間的距離或幅度，因此對特徵縮放不敏感。

### 76. 成本敏感學習(Cost-sensitive Learning)主要解決什麼問題？
A. 過擬合  
B. 類別不平衡  
C. 特徵過多  
D. 數據缺失

**正確答案：B**  
**解析：** 成本敏感學習通過賦予少數類更高的誤分類代價，來解決類別不平衡問題。

### 77. 關於訓練集、驗證集和測試集的劃分比例，常見的是？
A. 30:30:40  
B. 60:20:20 或 80:10:10  
C. 10:10:80  
D. 50:50:0

**正確答案：B**  
**解析：** 常見的劃分比例通常是訓練集佔大部分(60-80%)，驗證集和測試集各佔10-20%。

### 78. 如果訓練集誤差高，測試集誤差也高，這是什麼現象？
A. 過擬合 (High Variance)  
B. 欠擬合 (High Bias)  
C. 數據洩露  
D. 最優狀態

**正確答案：B**  
**解析：** 訓練集和測試集誤差都高，說明模型沒有學好，是欠擬合(High Bias)。

### 79. 如果訓練集誤差低，測試集誤差高，這是什麼現象？
A. 過擬合 (High Variance)  
B. 欠擬合 (High Bias)  
C. 模型太簡單  
D. 數據太少

**正確答案：A**  
**解析：** 訓練集表現好但測試集表現差，說明模型泛化能力差，是過擬合(High Variance)。

### 80. 在選擇模型時，"No Free Lunch" 定理告訴我們？
A. 肯定有一個模型在所有問題上都是最好的  
B. 沒有一個模型在所有問題上都能表現最好  
C. 免費的模型通常不好  
D. 簡單模型總是比複雜模型好

**正確答案：B**  
**解析：** No Free Lunch 定理指出，沒有一種演算法能在所有可能的問題上都優於其他演算法，必須根據具體問題選擇合適的模型。

---

## 答案總覽

| 題號 | 答案 | 題號 | 答案 | 題號 | 答案 | 題號 | 答案 |
|------|------|------|------|------|------|------|------|
| 1 | B | 21 | B | 41 | B | 61 | B |
| 2 | B | 22 | C | 42 | B | 62 | A |
| 3 | B | 23 | B | 43 | D | 63 | B |
| 4 | C | 24 | C | 44 | B | 64 | B |
| 5 | B | 25 | B | 45 | C | 65 | B |
| 6 | B | 26 | B | 46 | C | 66 | B |
| 7 | C | 27 | C | 47 | B | 67 | C |
| 8 | B | 28 | C | 48 | C | 68 | C |
| 9 | C | 29 | B | 49 | C | 69 | B |
| 10 | C | 30 | B | 50 | C | 70 | C |
| 11 | C | 31 | C | 51 | B | 71 | C |
| 12 | B | 32 | B | 52 | D | 72 | C |
| 13 | C | 33 | B | 53 | B | 73 | B |
| 14 | C | 34 | A | 54 | C | 74 | B |
| 15 | B | 35 | B | 55 | B | 75 | D |
| 16 | C | 36 | C | 56 | B | 76 | B |
| 17 | C | 37 | B | 57 | C | 77 | B |
| 18 | B | 38 | B | 58 | B | 78 | B |
| 19 | A | 39 | C | 59 | B | 79 | A |
| 20 | C | 40 | B | 60 | A | 80 | B |
