# 統計學在大數據中的應用 - 80題單選題題庫

基於 L22301_統計學在大數據中的應用.md

考試日期：2026/05/23

---

## 第一部分：大數據統計特點與挑戰 (20題)

### 1. 傳統統計學與大數據統計學的一個主要差異在於？
A. 傳統統計學不使用數學  
B. 大數據統計學通常處理樣本量極大 (n → ∞) 的情況  
C. 傳統統計學只處理文字  
D. 大數據統計學不關心誤差

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 大數據最顯著的特徵是數據量巨大，往往接近全體母體，這與傳統小樣本推論有很大不同。

</details>

### 2. 在大數據環境下，數據維度 (Dimensionality) 通常？
A. 很低  
B. 很高，變數數量極多  
C. 只有一個變數  
D. 不重要

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 高維度是大數據的典型特徵，所謂「維度災難」也是由此而來。

</details>

### 3. 非結構化數據的例子包括？
A. Excel 表格  
B. 關聯式資料庫的 Row  
C. 文本、圖像、音頻、視頻  
D. CSV 文件

<details>
<summary>顯示答案</summary>

**正確答案：C**  
**解析：** 非結構化數據沒有預定義的數據模型，多媒體和自然語言文本是典型代表。

</details>

### 4. 大數據分析對時間的要求通常是？
A. 越慢越好  
B. 即時性 (Real-time) 要求高  
C. 只有在年底才分析  
D. 不在乎時間

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 大數據應用往往需要快速響應，例如實時詐欺檢測或推薦。

</details>

### 5. 當樣本量 n 趨近於無窮大時，傳統假設檢定中的 p值容易？
A. 變得非常大  
B. 變得非常小 (趨近於 0)，導致即使微小的差異也會顯著  
C. 保持不變  
D. 失去意義

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 大樣本下，標準誤變得極小，統計檢定力極高，微不足道的差異也會呈現統計顯著。

</details>

### 6. 處理高維度數據時的主要挑戰是？
A. 計算速度太快  
B. 數據過於稀疏，距離度量失效 (維度災難)  
C. 硬碟裝不下  
D. 可視化太簡單

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 在高維空間中，數據點變得稀疏，距離概念變得模糊，導致許多傳統算法失效。

</details>

### 7. 大數據環境下的抽樣策略為何仍然重要？
A. 電腦跑不動全量數據  
B. 為了節省計算資源，快速獲得近似結果  
C. 抽樣比全量更準確  
D. 為了增加誤差

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 雖然大數據強調全量，但在實時性要求高或資源有限時，科學的抽樣仍是高效手段。

</details>

### 8. 近似演算法 (Approximate Algorithms) 的目標是？
A. 獲得絕對精確的解  
B. 在可接受的誤差範圍內，大幅提高計算效率  
C. 隨機猜測  
D. 增加計算複雜度

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 在大數據場景，犧牲一點精度換取速度往往是必要的權衡。

</details>

### 9. 增量計算 (Incremental Computation) 是指？
A. 每次有新數據都重新計算所有歷史數據  
B. 只針對新增數據進行計算，並更新現有結果  
C. 刪除舊數據  
D. 增加硬體

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 增量計算避免了重複運算，適合流式數據或實時更新場景。

</details>

### 10. 分散式統計計算通常依賴什麼架構？
A. 單機 Excel  
B. 叢集計算框架 (如 Hadoop, Spark)  
C. 計算機  
D. 手機

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 數據量超過單機負荷，必須透過多台機器並行運算。

</details>

### 11. 關於大數據中的 "全量數據"，下列觀點何者正確？
A. 代表絕對的真理  
B. 代表母體，不再需要推論統計  
C. 仍然可能存在偏差 (Bias)，例如採樣偏差  
D. 數據品質總是完美的

<details>
<summary>顯示答案</summary>

**正確答案：C**  
**解析：** 即使數據量大，如果數據來源本身有偏（例如只來自社交媒體用戶），結果依然有偏。

</details>

### 12. 什麼是 "MapReduce" 在統計計算中的作用？
A. 繪製地圖  
B. 將統計任務分解為並行處理 (Map) 和 匯總 (Reduce)  
C. 減少數據量  
D. 增加維度

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 這是一種適合大規模數據集並行運算的編程模型，常用於計算頻率、均值等統計量。

</details>

### 13. 大數據統計中，"相關性" 與 "因果性" 的關係是？
A. 相關性等同於因果性  
B. 大數據更擅長發現相關性，但推斷因果性仍需謹慎  
C. 只需要因果性  
D. 兩者無關

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 大數據可以輕易找出變數間的關聯，但要證明因果關係仍需實驗設計或更嚴謹的因果推論。

</details>

### 14. 數據稀疏性 (Sparsity) 常見於哪種應用？
A. 簡單的問卷調查  
B. 推薦系統 (用戶-商品矩陣)  
C. 時間序列  
D. 溫度記錄

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 用戶通常只評價了極少部分的商品，導致矩陣大部分元素為空。

</details>

### 15. 在實時分析中，我們通常犧牲什麼來換取速度？
A. 準確性 (使用近似解)  
B. 數據量  
C. 可用性  
D. 安全性

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 為了達到毫秒級響應，常使用 HyperLogLog 等近似算法。

</details>

### 16. 分層抽樣 (Stratified Sampling) 在大數據中的應用是為了？
A. 確保稀有類別也能被抽到，保持樣本代表性  
B. 隨機抽取  
C. 只抽取頭部數據  
D. 簡化流程

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 在類別不平衡的大數據中，分層抽樣能確保小群體不被淹沒。

</details>

### 17. 集群抽樣 (Cluster Sampling) 適用於？
A. 數據自然分組且組內差異大、組間差異小的情況  
B. 數據完全均勻  
C. 數據量很小  
D. 需要最高精度

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 當數據分散在不同節點或地理區域時，集群抽樣可以降低成本。

</details>

### 18. 並行計算 (Parallel Computing) 的主要瓶頸通常是？
A. CPU 速度  
B. 節點間的通訊與數據傳輸 (Network Overhead)  
C. 硬碟容量  
D. 螢幕解析度

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 數據洗牌 (Shuffle) 或同步狀態造成的網絡延遲往往限制了擴展性。

</details>

### 19. 在大數據中，異常值 (Outliers) 的影響？
A. 變小，因為被淹沒了  
B. 變大，因為數據量大  
C. 可能代表重要的商業機會 (如欺詐、爆款)，也可能是噪音  
D. 直接刪除

<details>
<summary>顯示答案</summary>

**正確答案：C**  
**解析：** 大數據分析常專注於異常偵測，因為它們往往蘊含高價值信息。

</details>

### 20. 數據的 "Velocity" (速度) 特性要求統計方法？
A. 必須是靜態的  
B. 能夠處理流式數據，支持在線學習 (Online Learning)  
C. 只能處理歷史數據  
D. 不需要算法

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 高速產生的數據要求模型能隨數據流動態更新。

</details>

---

## 第二部分：統計分析與近似方法 (20題)

### 21. 對於大規模數據的平均數計算，分散式環境下通常如何做？
A. 將所有數據拉到一台機器計算  
B. 各節點計算局部總和與計數，再匯總計算全局平均  
C. 隨機估計  
D. 無法計算

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 這是典型的 MapReduce 聚合模式，避免單點瓶頸。

</details>

### 22. HyperLogLog 演算法主要用於解決什麼問題？
A. 排序  
B. 基數估計 (Cardinality Estimation)，如計算網站有多少獨立訪客 (UV)  
C. 聚類  
D. 回歸

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** HyperLogLog 能以極小的內存誤差極低地估計去重後的數量。

</details>

### 23. 為什麼在大數據中常使用中位數的近似算法 (如 T-Digest)？
A. 因為中位數不重要  
B. 精確計算中位數需要全排序，對大數據而言代價過高  
C. 近似算法更準確  
D. 為了省電

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 分位數（含中位數）的精確計算難以並行化且消耗資源，近似算法是實用的選擇。

</details>

### 24. 布隆過濾器 (Bloom Filter) 用於？
A. 精確判斷元素是否存在  
B. 快速判斷元素 "絕對不存在" 或 "可能存在"  
C. 數據加密  
D. 數據壓縮

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 空間效率極高的概率型數據結構，常用於去重或緩存穿透防護。

</details>

### 25. 蓄水池抽樣 (Reservoir Sampling) 適用於？
A. 已知大小的靜態數據集  
B. 未知大小、源源不斷的流數據，需保持等機率隨機抽取  
C. 分層抽樣  
D. 異常檢測

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 確保在流式數據中，每個元素被選中的機率相等。

</details>

### 26. 描述性統計在大數據中的第一步通常是？
A. 建立復雜模型  
B. 數據摘要 (Data Summarization) 與可視化探索  
C. 刪除數據  
D. 預測未來

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 先了解數據的基本分佈和特徵是後續分析的基礎。

</details>

### 27. Count-Min Sketch 是一種用於什麼的數據結構？
A. 頻率估計 (Frequency Estimation)  
B. 圖像處理  
C. 路徑規劃  
D. 文本生成

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 用於在流數據中估計元素出現的頻率，空間換時間，允許少量誤差。

</details>

### 28. Bootstrap 方法是一種？
A. 參數估計方法  
B. 重抽樣 (Resampling) 技術，用於估計統計量的分佈  
C. 降維技術  
D. 聚類算法

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 通過從原始樣本中重複有放回抽樣來模擬抽樣分佈，特別適合沒有公式解的複雜統計量。

</details>

### 29. 大樣本理論 (Large Sample Theory) 告訴我們？
A. 樣本越大越好  
B. 隨著樣本量增加，統計量的抽樣分佈趨向於常態分佈 (中心極限定理)  
C. 大樣本不需要統計  
D. 樣本量無關緊要

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 這是許多統計推論方法的理論基礎。

</details>

### 30. 在大數據中，為何有時 "簡單模型 + 大量數據" 優於 "複雜模型 + 少量數據"？
A. 複雜模型容易過擬合 (Overfitting)  
B. 簡單模型計算快，且大數據能彌補模型的偏差  
C. 複雜模型沒用  
D. 簡單模型更貴

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 著名的 "Unreasonable Effectiveness of Data"，足夠的數據可以讓簡單算法表現出色。

</details>

### 31. 近似統計量的一個缺點是？
A. 計算慢  
B. 存在估計誤差  
C. 佔用內存多  
D. 難以實現

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 這是用準確性換取效率的必然代價。

</details>

### 32. 如何評估近似演算法的好壞？
A. 只看速度  
B. 權衡準確性 (誤差界限) 與 資源消耗 (時間/空間)  
C. 只看代碼行數  
D. 只看名稱

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 好的近似算法應在極大節省資源的同時，將誤差控制在可接受範圍內。

</details>

### 33. 分散式計算計算標準差時，需要維護哪些中間值？
A. 只有總和  
B. 計數 (Count)、總和 (Sum)、平方和 (Sum of Squares)  
C. 只有平均值  
D. 所有原始數據

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 利用 E(X^2) - (E(X))^2 公式，可以並行計算這三個統計量來導出變異數和標準差。

</details>

### 34. 實時儀表板 (Dashboard) 通常展示的是？
A. 原始日誌  
B. 聚合後的描述性統計指標 (如 PV, UV, 銷售額)  
C. 未來預測  
D. 代碼

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 管理者需要看到的是經過摘要的關鍵績效指標 (KPI)。

</details>

### 35. 數據分箱 (Binning) 或直方圖近似在大數據中用於？
A. 了解數據分佈形狀  
B. 增加數據量  
C. 加密  
D. 備份

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 通過將連續數據離散化，快速掌握數據的分佈情況。

</details>

### 36. 局部敏感雜湊 (LSH) 主要用於？
A. 精確匹配  
B. 近似最近鄰搜索 (Approximate Nearest Neighbor)，快速找到相似項目  
C. 數據排序  
D. 數據刪除

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 用於在大規模高維數據中快速查找相似的對象（如圖片去重、相似文檔）。

</details>

### 37. 當數據量大到無法全部載入記憶體時，這種算法稱為？
A. 內存算法  
B. 外存算法 (External Memory Algorithm) 或 串流算法  
C. 雲端算法  
D. 遞歸算法

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 利用磁碟I/O進行分批處理的算法。

</details>

### 38. Jackknife 方法與 Bootstrap 類似，但它是透過什麼方式重抽樣？
A. 有放回抽樣  
B. 每次刪除一個觀察值 (Leave-one-out)  
C. 增加數據  
D. 隨機生成

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 用於估計偏差和標準誤。

</details>

### 39. 對於偏態嚴重的大數據分佈，哪個統計量比平均數更具代表性？
A. 眾數  
B. 中位數 (分位數)  
C. 標準差  
D. 變異數

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 中位數穩健性高，抗極端值干擾。

</details>

### 40. 漸近分佈 (Asymptotic Distribution) 是指？
A. 樣本量無限大時的極限分佈  
B. 樣本量為 0 的分佈  
C. 均勻分佈  
D. 錯誤的分佈

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 統計推論在大數據中常依賴漸近性質。

</details>

---

## 第三部分：多變量分析與機器學習 (25題)

### 41. 主成分分析 (PCA) 的主要目的是？
A. 增加變數數量  
B. 降維 (Dimensionality Reduction)，保留數據主要變異  
C. 分類  
D. 預測

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 將高維相關變數轉換為少數線性無關的主成分。

</details>

### 42. 在大數據中，為何需要降維？
A. 為了好看  
B. 減少計算量，避免維度災難，去除噪聲  
C. 增加存儲空間  
D. 增加複雜度

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 去除冗餘特徵，提升模型效率和效果。

</details>

### 43. 聚類分析 (Cluster Analysis) 屬於哪種學習方式？
A. 監督學習  
B. 無監督學習 (Unsupervised Learning)  
C. 強化學習  
D. 半監督學習

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 數據沒有標籤，算法自動發現數據的內在分組結構。

</details>

### 44. K-means 聚類在大數據中的挑戰是？
A. 算法太簡單  
B. 對初始中心敏感，且迭代計算量大  
C. 只支持二維數據  
D. 不需要計算距離

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 每次迭代都要計算所有點到中心的距離，大數據下開銷大，常使用 Mini-batch K-means。

</details>

### 45. 因子分析 (Factor Analysis) 與 PCA 的區別在於？
A. 兩者完全一樣  
B. PCA 是線性變換，因子分析假設存在潛在的隱變量 (Latent Factors)  
C. PCA 用於分類，因子分析用於聚類  
D. 因子分析不能降維

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 因子分析試圖解釋變數間的共變異數結構，更側重於模型解釋。

</details>

### 46. 判別分析 (Discriminant Analysis) 主要用於？
A. 降維  
B. 分類 (Classification)，找出區分不同類別的特徵組合  
C. 聚類  
D. 關聯規則

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 如 LDA (線性判別分析)，既降維又最大化類間差異。

</details>

### 47. 關聯規則學習 (Association Rule Learning) 的經典算法是？
A. K-means  
B. Apriori 或 FP-Growth  
C. SVM  
D. PCA

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 用於發現 "啤酒與尿布" 這類的共現關係。

</details>

### 48. 支持度 (Support) 在關聯規則中表示？
A. 規則的可信度  
B. 某項集在所有事務中出現的頻率  
C. 提升度  
D. 錯誤率

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** P(A∩B)，衡量規則的覆蓋範圍。

</details>

### 49. 置信度 (Confidence) 在關聯規則中表示？
A. P(B|A)，即包含 A 的事務中同時包含 B 的機率  
B. P(A)  
C. P(B)  
D. 規則的長度

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 衡量規則的準確性或強度。

</details>

### 50. 奇異值分解 (SVD) 常用於？
A. 推薦系統 (矩陣分解)  
B. 排序  
C. 搜索  
D. 加密

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 將用戶-評分矩陣分解，發現潛在特徵以預測評分。

</details>

### 51. 隨機森林 (Random Forest) 通過什麼技術提高準確性？
A. 單一決策樹  
B. Bagging (Bootstrap Aggregating) 集成多棵樹  
C. 線性回歸  
D. 降維

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 透過隨機抽樣構建多樣化的樹並投票，降低過擬合風險。

</details>

### 52. 邏輯回歸 (Logistic Regression) 常用於處理什麼問題？
A. 連續數值預測  
B. 二元分類 (Binary Classification)  
C. 圖片生成  
D. 聚類

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 預測事件發生的機率 (0或1)。

</details>

### 53. 在高維數據中，距離度量 (如歐氏距離) 可能會？
A. 變得更有意義  
B. 失效，所有點之間的距離趨於相等  
C. 變為負數  
D. 變為 0

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 這是維度災難的典型表現，對依賴距離的算法 (KNN, K-means) 影響巨大。

</details>

### 54. t-SNE 是一種什麼技術？
A. 線性降維  
B. 非線性降維與可視化技術 (特別適合高維數據映射到 2D/3D)  
C. 聚類算法  
D. 回歸算法

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 能很好地保留局部結構，常用於數據探索可視化。

</details>

### 55. 梯度下降 (Gradient Descent) 在大數據中通常使用什麼變體？
A. 批量梯度下降 (BGD)  
B. 隨機梯度下降 (SGD) 或 Mini-batch SGD  
C. 不使用梯度下降  
D. 解析解

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 全量 BGD 計算太慢，SGD 每次只用一個或一批樣本更新，收斂更快且可處理大數據。

</details>

### 56. 特徵選擇 (Feature Selection) 的目的是？
A. 選擇最重要的特徵子集，去除無關特徵  
B. 創造新特徵  
C. 增加數據量  
D. 備份特徵

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 減少維度，防止過擬合，提高可解釋性。

</details>

### 57. 正規化 (Regularization) (如 L1, L2) 用於？
A. 加快訓練  
B. 防止模型過擬合 (Overfitting)  
C. 增加模型複雜度  
D. 清除數據

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 通過懲罰過大的參數值來限制模型複雜度。

</details>

### 58. 交叉驗證 (Cross-Validation) 在大數據中依然重要，是因為？
A. 評估模型的泛化能力  
B. 增加訓練時間  
C. 消耗計算資源  
D. 用戶喜歡

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 確保模型在未見過的數據上也能表現良好。

</details>

### 59. 混淆矩陣 (Confusion Matrix) 用於評估？
A. 回歸模型  
B. 分類模型的性能  
C. 聚類效果  
D. 數據品質

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 顯示 TP, TN, FP, FN 等指標。

</details>

### 60. ROC 曲線與 AUC 值用於評估？
A. 回歸模型  
B. 二分類模型在不同閾值下的表現  
C.聚類模型  
D. 降維效果

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 衡量模型區分正負樣本的能力，AUC 越接近 1 越好。

</details>

### 61. PCA 提取的第一主成分具有什麼特性？
A. 解釋了數據中最大的變異 (Variance)  
B. 解釋了最小的變異  
C. 與第二主成分相關  
D. 沒有意義

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 投影后數據分佈最廣的方向。

</details>

### 62. K-means 中的 "K" 代表？
A. 迭代次數  
B. 聚類的簇數 (Clusters)  
C. 數據維度  
D. 樣本數

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 需要預先指定的分群數量。

</details>

### 63. 決策樹在大數據中的優勢是？
A. 可解釋性強  
B. 計算最快  
C. 永遠準確  
D. 不佔內存

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 規則清晰，易於理解業務邏輯。

</details>

### 64. 協同過濾 (Collaborative Filtering) 依賴於？
A. 用戶的行為數據 (評分、購買)  
B. 商品的屬性  
C. 專家的規則  
D. 隨機推薦

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** "喜歡 A 的人也喜歡 B"。

</details>

### 65. 文本挖掘中的 TF-IDF 用於？
A. 計算詞頻  
B. 衡量一個詞在文檔中的重要程度 (過濾常見詞)  
C. 翻譯  
D. 拼寫檢查

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 詞頻高但逆文檔頻率也高（即在其他文檔少見）的詞才具區分力。

</details>

---

## 第四部分：應用與工具 (15題)

### 66. Spark MLlib 的主要功能是？
A. 繪圖  
B. 提供可擴展的機器學習算法庫  
C. 資料庫管理  
D. 網頁伺服器

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 專為大數據設計的分散式 ML 算法。

</details>

### 67. 在 Python 中，處理大數據統計分析的常用庫是？
A. Pandas (單機) / PySpark (分散式)  
B. PyGame  
C. Flask  
D. Requests

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** Pandas 適合中小數據，PySpark 處理海量數據。

</details>

### 68. 數據科學專案的標準流程通常是？
A. CRISP-DM (跨行業數據挖掘標準流程)  
B. 只有編碼  
C. 只有繪圖  
D. 隨意進行

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 理解業務 -> 理解數據 -> 準備數據 -> 建模 -> 評估 -> 部署。

</details>

### 69. A/B 測試在大數據產品迭代中的作用？
A. 隨機決定功能  
B. 通過對照實驗，用統計數據量化新功能的影響  
C. 節省開發時間  
D. 尋找 bug

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 數據驅動決策的黃金標準。

</details>

### 70. 辛普森悖論 (Simpson's Paradox) 提醒我們？
A. 數據總是對的  
B. 聚合數據看到的趨勢可能與分組數據看到的趨勢相反 (忽略了潛在變數)  
C. 不要分組  
D. 統計學沒用

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 統計陷阱，強調細分分析的重要性。

</details>

### 71. "Data Lakehouse" 架構試圖結合？
A. 數據湖的靈活性與數據倉庫的管理能力  
B. 數據庫與 Excel  
C. 批次與串流  
D. 軟體與硬體

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 現代數據架構趨勢，支持 ACID 和大數據分析。

</details>

### 72. 社交網絡分析的核心是？
A. 文本分析  
B. 圖論 (Graph Theory) 與 網絡統計量 (如中心性)  
C. 圖像識別  
D. 回歸分析

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 分析節點 (人) 與邊 (關係) 的結構。

</details>

### 73. 情感分析 (Sentiment Analysis) 屬於統計學在什麼領域的應用？
A. 圖像處理  
B. 自然語言處理 (NLP)  
C. 語音識別  
D. 生物信息

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 判斷文本的情緒傾向 (正/負面)。

</details>

### 74. 在推薦系統中，"冷啟動" 問題是指？
A. 電腦太冷  
B. 對於新用戶或新商品，缺乏歷史數據導致無法推薦  
C.系統啟動慢  
D. 推薦結果太冷門

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 無行為數據時無法計算相似度。

</details>

### 75. 隱私計算 (Privacy-preserving Computation) 如聯邦學習，目的是？
A. 公開所有數據  
B. 在保護數據隱私 (不交換原始數據) 的前提下進行聯合建模  
C. 停止建模  
D. 加密硬碟

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 解決數據孤島與隱私保護的矛盾。

</details>

### 76. 蒙地卡羅模擬 (Monte Carlo Simulation) 依靠什麼來解決問題？
A. 精確公式  
B. 大量的隨機抽樣  
C. 邏輯推理  
D. 專家意見

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 通過模擬成千上萬種可能的隨機路徑來估計結果機率。

</details>

### 77. 貝葉斯統計 (Bayesian Statistics) 的特點是？
A. 頻率學派  
B. 結合先驗機率 (Prior) 與觀察數據 (Likelihood) 更新後驗機率 (Posterior)  
C. 不使用機率  
D. 只看數據

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 動態更新信念的統計推論框架。

</details>

### 78. 異常檢測 (Anomaly Detection) 在資安領域的應用是？
A. 檢測黑客入侵 (Intrusion Detection)  
B. 備份文件  
C. 加密郵件  
D. 網站加速

<details>
<summary>顯示答案</summary>

**正確答案：A**  
**解析：** 識別偏離正常行為模式的流量或操作。

</details>

### 79. 數據傳輸中的 "序列化" (Serialization) 是為了？
A. 加密  
B. 將對象轉換為可存儲或傳輸的字節流格式  
C. 排序  
D. 壓縮

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 如 JSON, Avro, Protobuf 等格式。

</details>

### 80. 統計學在大數據時代的地位？
A. 已被 AI 取代  
B. 更加重要，是機器學習和數據分析的理論基石  
C. 變得無關緊要  
D. 只用於畫圖

<details>
<summary>顯示答案</summary>

**正確答案：B**  
**解析：** 機器學習本質上就是統計學習，大數據挖掘離不開統計思維。

</details>

---

## 答案總覽

| 題號 | 答案 | 題號 | 答案 | 題號 | 答案 | 題號 | 答案 |
|------|------|------|------|------|------|------|------|
| 1 | B | 21 | B | 41 | B | 61 | A |
| 2 | B | 22 | B | 42 | B | 62 | B |
| 3 | C | 23 | B | 43 | B | 63 | A |
| 4 | B | 24 | B | 44 | B | 64 | A |
| 5 | B | 25 | B | 45 | B | 65 | B |
| 6 | B | 26 | B | 46 | B | 66 | B |
| 7 | B | 27 | A | 47 | B | 67 | A |
| 8 | B | 28 | B | 48 | B | 68 | A |
| 9 | B | 29 | B | 49 | A | 69 | B |
| 10 | B | 30 | B | 50 | A | 70 | B |
| 11 | C | 31 | B | 51 | B | 71 | A |
| 12 | B | 32 | B | 52 | B | 72 | B |
| 13 | B | 33 | B | 53 | B | 73 | B |
| 14 | B | 34 | B | 54 | B | 74 | B |
| 15 | A | 35 | A | 55 | B | 75 | B |
| 16 | A | 36 | B | 56 | A | 76 | B |
| 17 | A | 37 | B | 57 | B | 77 | B |
| 18 | B | 38 | B | 58 | A | 78 | A |
| 19 | C | 39 | B | 59 | B | 79 | B |
| 20 | B | 40 | A | 60 | B | 80 | B |
