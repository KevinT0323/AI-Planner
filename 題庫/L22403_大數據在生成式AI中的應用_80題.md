# 大數據在生成式AI中的應用 - 80題單選題題庫

基於 L22403_大數據在生成式AI中的應用.md

考試日期：2026/05/23

---

## 第一部分：大規模預訓練與語言模型 (20題)

### 1. 生成式 AI (Generative AI) 的核心目標是？
A. 僅分類現有數據  
B. 學習數據的分布，創造出新的、逼真的數據 (如文本、圖像)  
C. 壓縮數據  
D. 刪除數據

**正確答案：B**  
**解析：** 生成式 AI 旨在創造新內容，區別於鑑別式 AI 的分類功能。

### 2. 訓練現代大語言模型 (LLM) 所需的文本數據量級通常是？
A. 幾 MB (兆字節)  
B. 幾 GB (吉字節)  
C. 數 TB (太位元組) 甚至 PB 級的 Tokens  
D. 幾 KB

**正確答案：C**  
**解析：** 海量數據是湧現 (Emergence) 能力的基礎，如 GPT-3 使用了 45TB 的文本。

### 3. Transformer 架構之所以適合大規模預訓練，主要是因為？
A. 它參數少  
B. 它的並行計算能力強 (Self-Attention)，且能捕捉長距離依賴，適合處理海量數據  
C. 它基於循環神經網絡  
D. 它不需要 GPU

**正確答案：B**  
**解析：** 相比 RNN，Transformer 允許高效的並行訓練，大大縮短了訓練時間。

### 4. 語言模型的「自監督學習 (Self-Supervised Learning)」是如何獲取標籤的？
A. 僱傭大量人工標註  
B. 直接利用文本本身 (如 遮蓋住一個詞，讓模型預測它)，無需額外人工標籤  
C. 隨機生成  
D. 不使用標籤

**正確答案：B**  
**解析：** "Next Token Prediction" 或 "Masked Language Modeling" 是自監督學習的典型任務。

### 5. 「預訓練 + 微調 (Pre-training + Fine-tuning)」範式的優勢是？
A. 訓練速度最慢  
B. 模型只需在通用海量數據上預訓練一次，即可通過少量數據微調適應多種下游任務  
C. 每個任務都必須從頭訓練  
D. 只能用於英語

**正確答案：B**  
**解析：** 大幅降低了特定任務的模型開發成本和數據門檻。

### 6. 預訓練階段通常優化的目標是？
A. 特定的分類準確率  
B. 通用的語言理解與生成能力 (如 困惑度 Perplexity)  
C. 圖像識別  
D. 語音合成

**正確答案：B**  
**解析：** 讓模型學會 "說話"，理解語法和世界知識。

### 7. GPT (Generative Pre-trained Transformer) 系列模型主要採用什麼架構？
A. Encoder-only (如 BERT)  
B. Decoder-only (自回歸生成)  
C. Encoder-Decoder (如 T5)  
D. CNN

**正確答案：B**  
**解析：** 自回歸 (Auto-regressive) 架構最適合文本生成任務。

### 8. BERT 模型的預訓練任務之一是 MLM，全稱是？
A. Multi-Language Model  
B. Masked Language Modeling (掩碼語言模型)  
C. Machine Learning Model  
D. Maximum Likelihood Method

**正確答案：B**  
**解析：** 隨機遮蓋詞並預測，迫使模型理解上下文。

### 9. 強化學習從人類反饋中學習 (RLHF) 的作用是？
A. 讓模型學會下棋  
B. 使模型的輸出更符合人類的價值觀、偏好和指令 (Alignment)  
C. 增加模型參數量  
D. 減少訓練時間

**正確答案：B**  
**解析：** ChatGPT 的關鍵技術，讓模型變 "聽話"。

### 10. 大模型出現的「幻覺 (Hallucination)」問題是指？
A. 模型看到鬼  
B. 模型一本正經地胡說八道，生成看似合理但事實錯誤的內容  
C. 模型拒絕回答  
D. 模型生成亂碼

**正確答案：B**  
**解析：** 生成式 AI 的固有特性，需要通過 RAG 或其他技術緩解。

### 11. 上下文窗口 (Context Window) 的大小限制了？
A. 模型的參數量  
B. 模型一次能處理的輸入/輸出文本長度 (短期記憶)  
C. 訓練數據量  
D. 詞彙表大小

**正確答案：B**  
**解析：** 窗口越大，模型能記住的對話歷史或處理的文檔越長。

### 12. 縮放定律 (Scaling Laws) 表明，模型的性能與什麼呈冪律關係？
A. 時間、地點、人物  
B. 計算量 (Compute)、數據集大小 (Data Size)、參數數量 (Parameters)  
C. 開發者人數  
D. 電腦品牌

**正確答案：B**  
**解析：** 只要增加算力、數據和參數，性能就會可預測地提升。

### 13. Tokenizer (分詞器) 的作用是？
A. 翻譯  
B. 將文本分割並轉換為模型可處理的數字序列 (ID)  
C. 生成圖像  
D. 壓縮模型

**正確答案：B**  
**解析：** BPE (Byte Pair Encoding) 是常用的分詞算法。

### 14. 提示工程 (Prompt Engineering) 的目的是？
A. 修改模型參數  
B. 通過設計精巧的輸入文本 (Prompt)，引導凍結參數的模型生成期望的輸出  
C. 訓練模型  
D. 數據標註

**正確答案：B**  
**解析：** 在不重新訓練模型的情況下激發其能力。

### 15. 思維鏈 (Chain-of-Thought) 提示能顯著提升大模型在哪方面的能力？
A. 圖像生成  
B. 複雜邏輯推理和數學解題 (通過讓模型展示思考過程)  
C. 拼寫檢查  
D. 情感分析

**正確答案：B**  
**解析：** "Let's think step by step."

### 16. 參數高效微調 (PEFT) 如 LoRA 的特點是？
A. 微調所有參數  
B. 凍結大部分预訓練參數，只訓練極少量新增參數 (低秩矩陣)，大幅降低顯存需求  
C. 不訓練參數  
D. 增加參數量

**正確答案：B**  
**解析：** 讓個人開發者也能微調大模型。

### 17. 檢索增強生成 (RAG) 通過什麼解決幻覺和知識過時問題？
A. 增加訓練數據  
B. 在生成前先從外部知識庫檢索相關信息，作為上下文餵給模型  
C. 增大模型參數  
D. 延長訓練時間

**正確答案：B**  
**解析：** 給開卷考試的學生發課本。

### 18. 用於訓練大語言模型的數據通常來自？
A. 只有維基百科  
B. 互聯網爬蟲 (Common Crawl)、書籍、代碼庫、論文等多樣化來源  
C. 人工手寫  
D. 只有對話記錄

**正確答案：B**  
**解析：** 數據的多樣性決定了模型的通用性。

### 19. 在預訓練數據中去重 (Deduplication) 的重要性？
A. 不重要  
B. 防止模型死記硬背 (Memorization)，提高訓練效率和泛化能力  
C. 為了減少硬碟佔用  
D. 為了增加多樣性

**正確答案：B**  
**解析：** 重複數據會導致模型過擬合特定句子，而非學習規律。

### 20. 混合專家 (MoE) 架構在推理時的優勢？
A. 激活所有參數  
B. 對於每個 Token 只激活部分專家網絡 (Sparse Activation)，在保持大參數量的同時降低計算成本  
C. 精度最高  
D. 結構最簡單

**正確答案：B**  
**解析：** GPT-4 等先進模型採用的架構。

---

## 第二部分：圖像生成與擴散模型 (20題)

### 21. 生成對抗網路 (GAN) 由哪兩部分組成？
A. Encoder, Decoder  
B. Generator (生成器), Discriminator (判別器)  
C. Actor, Critic  
D. Map, Reduce

**正確答案：B**  
**解析：** 生成器負責造假，判別器負責抓假，兩者對抗訓練。

### 22. 擴散模型 (Diffusion Model) 的生成過程是？
A. 一次性生成  
B. 從高斯噪聲開始，通過逐步去噪 (Denoising) 還原出清晰圖像  
C. 拼接圖片  
D. 檢索圖片

**正確答案：B**  
**解析：** 這是 Stable Diffusion, Midjourney 等現代圖像生成模型的基礎。

### 23. 擴散模型相比 GAN 的主要優勢是？
A. 生成速度更快  
B. 訓練更穩定，生成的樣本多樣性更好 (不易發生 Mode Collapse)  
C. 機制更簡單  
D. 不需要數據

**正確答案：B**  
**解析：** 雖然推理慢，但在生成質量和多樣性上超越了 GAN。

### 24. 在 Stable Diffusion 中，CLIP模型的作用是？
A. 生成圖像  
B. 連接文本和圖像，將文本提示詞 (Prompt) 引導圖像生成方向  
C. 壓縮圖像  
D. 去噪

**正確答案：B**  
**解析：** 讓文字能夠控制圖像內容 (Text-to-Image)。

### 25. 潛在擴散模型 (Latent Diffusion) 為何比像素級擴散快？
A. 它在低維的潛在空間 (Latent Space) 進行擴散過程，而非直接在像素空間處理  
B. 它忽略了細節  
C. 它使用了超級電腦  
D. 它不進行擴散

**正確答案：A**  
**解析：** 大幅降低了計算量，使得在消費級顯卡上運行成為可能。

### 26. 條件生成 (Conditional Generation) 是指？
A. 隨機生成  
B. 根據給定的條件 (如 文本描述、類別標籤、草圖) 生成內容  
C. 無條件生成  
D. 生成條件

**正確答案：B**  
**解析：** 讓生成過程可控。

### 27. ControlNet 用於？
A. 網絡安全  
B. 為擴散模型添加額外的空間控制條件 (如 邊緣圖、骨架圖、深度圖)，精確控制構圖  
C. 加速生成  
D. 提高解析度

**正確答案：B**  
**解析：** 解決了 "文生圖" 難以精確控制姿勢和輪廓的問題。

### 28. VAE (變分自編碼器) 的解碼器生成的是？
A. 確定性輸出  
B. 從潛在分佈採樣後重構的圖像，通常略微模糊  
C. 分類標籤  
D. 文本

**正確答案：B**  
**解析：** 早期的生成模型，理論優美但畫質不如 GAN/Diffusion。

### 29. 圖像生成中的 Inpainting 是指？
A. 在圖片上畫畫  
B. 修復或替換圖像中被遮擋或缺失的區域 (局部重繪)  
C. 擴展圖像邊界  
D. 風格遷移

**正確答案：B**  
**解析：** 常用于去除路人、換臉或修復老照片。

### 30. Outpainting 是指？
A. 刪除圖像  
B. 向外擴展圖像的邊界，想像畫框之外的內容  
C. 縮小圖像  
D. 變換風格

**正確答案：B**  
**解析：** 補全畫面之外的世界。

### 31. 風格遷移 (Style Transfer) 能做到？
A. 將一張圖的內容與另一張圖的藝術風格 (如 梵高星空) 融合  
B. 改變圖片大小  
C. 識別物體  
D. 壓縮圖片

**正確答案：A**  
**解析：** 讓普通照片變成名畫風格。

### 32. 大規模圖像數據集 LAION-5B 特點是？
A. 包含 50 億個圖像-文本對 (Image-Text Pairs)  
B. 收費  
C. 只有圖像沒有文本  
D. 只有人臉

**正確答案：A**  
**解析：** 開源的多模態數據集，支撐了開源圖像生成模型的發展。

### 33. CFG Scale (Classifier-Free Guidance Scale) 參數控制什麼？
A. 生成速度  
B. 生成圖像對提示詞 (Prompt) 的遵循程度 (越高越聽話，但可能犧牲質量)  
C. 圖像亮度  
D. 隨機性

**正確答案：B**  
**解析：** 平衡 "創意" 和 "聽話" 的關鍵參數。

### 34. 負向提示詞 (Negative Prompt) 的作用？
A. 批評模型  
B. 告訴模型 "不要" 生成什麼 (如 畸形的手、模糊、水印)  
C. 減少生成時間  
D. 沒作用

**正確答案：B**  
**解析：** 提升生成質量的實用技巧。

### 35. 擴散模型的採樣器 (Sampler) 如 Euler a_决定了？
A. 模型的結構  
B. 去噪過程的具體數學求解路徑 (影響生成速度和細節風格)  
C. 文本理解能力  
D. 圖像大小

**正確答案：B**  
**解析：** 不同的 Sampler 速度和畫風略有差異。

### 36. 圖像生成模型的 "Seed" (種子) 用於？
A. 加密  
B. 控制隨機初始噪聲，相同的 Seed 和參數能復現完全一樣的圖  
C. 種植植物  
D. 增加多樣性

**正確答案：B**  
**解析：** 確保生成結果的可重現性。

### 37. NeRF (神經輻射場) 是一種？
A. 2D 圖像生成技術  
B. 基於神經網絡的 3D 場景表示與渲染技術 (從 2D 照片合成新視角)  
C. 語音合成技術  
D. 文本生成技術

**正確答案：B**  
**解析：** AI 在 3D 重建領域的突破。

### 38. Sora (OpenAI) 是一個什麼模型？
A. 圖像編輯器  
B. 文本生成視頻模型 (Text-to-Video)，能生成長達一分鐘的連貫視頻  
C. 語音助手  
D. 遊戲引擎

**正確答案：B**  
**解析：** 視頻生成領域的里程碑，展現了對物理世界的模擬能力。

### 39. 生成模型評估指標 FID (Fréchet Inception Distance) 衡量？
A. 訓練時間  
B. 生成圖像與真實圖像分佈之間的距離 (數值越小，真實感和多樣性越好)  
C. 用戶評分  
D. 文件大小

**正確答案：B**  
**解析：** 衡量生成質量的客觀指標。

### 40. Deepfake (深偽) 技術主要基於？
A. 擴散模型  
B. GAN 或 Autoencoder，進行人臉替換與表情重演  
C. Photoshop  
D. 剪紙

**正確答案：B**  
**解析：** 引發了倫理和安全擔憂。

---

## 第三部分：數據需求與處理 (20題)

### 41. 訓練生成式 AI 對數據品質的要求是？
A. 只要量大，品質無所謂  
B. 高品質 (High Quality) 至關重要，低質數據會導致模型生成有毒、錯誤或無意義的內容  
C. 數據必須加密  
D. 只能用合成數據

**正確答案：B**  
**解析：** "Textbooks Are All You Need" 論文證明了高品質數據能顯著提升模型能力。

### 42. 數據多樣性 (Diversity) 對生成模型的影響？
A. 導致模型混亂  
B. 提高模泛化能力，使其能應對各種場景、風格和指令  
C. 沒影響  
D. 降低創造力

**正確答案：B**  
**解析：** 只有見過足夠多的世界，才能創造豐富的內容。

### 43. 數據平衡性 (Balance) 不足會導致？
A. 模型變快  
B. 模型偏見 (Bias)，過度生成優勢類別的內容，忽略少數群體  
C. 模型變大  
D. 訓練失敗

**正確答案：B**  
**解析：** 如性別刻板印象、種族偏見。

### 44. 數據清理在 LLM 預訓練中的步驟通常包括？
A. 去除 HTML 標籤、過濾色情暴力內容、去除低品質生成的文本、去重  
B. 加密所有文本  
C. 翻譯成英文  
D. 刪除所有數字

**正確答案：A**  
**解析：** 清洗是數據工程中最耗時但最重要的環節。

### 45. 合成數據 (Synthetic Data) 是指？
A. 人工手寫的數據  
B. 由 AI 模型生成的數據，用於訓練其他 AI 模型  
C. 假數據  
D. 錯誤數據

**正確答案：B**  
**解析：** 在高品質真實數據耗盡時，合成數據成為重要來源 (如 用 GPT-4 生成代碼訓練小模型)。

### 46. 數據標註在 RLHF 階段的形式通常是？
A. 給圖片打標籤  
B. 對模型生成的回复進行排序 (Ranking) 或打分，以此訓練獎勵模型 (Reward Model)  
C. 翻譯句子  
D. 糾錯

**正確答案：B**  
**解析：** 比較人類更喜歡哪一個回答。

### 47. 數據增強在 LLM 訓練中的應用？
A. 旋轉文字  
B. 不常用，因為網絡文本量已經足夠大，更多關注數據過濾和質量提升  
C. 隨機刪除字符  
D. 拼寫錯誤注入

**正確答案：B**  
**解析：** 與圖像不同，文本的語義對微小變化很敏感，且真實數據量已接近枯竭。

### 48. 數據隱私在生成式 AI 中是一個大問題，因為？
A. 模型可能會「記住」並在生成時洩露訓練數據中的敏感信息 (如 PII)  
B. 模型不會洩露  
C. 數據被刪除了  
D. 模型加密了

**正確答案：A**  
**解析：** 需要在訓練前進行脫敏處理 (PII Masking)。

### 49. 知識截止 (Knowledge Cutoff) 問題是因為？
A. 模型智商有限  
B. 模型的知識僅限於訓練數據收集的時間點，無法知道之後發生的事  
C. 硬碟滿了  
D. 開發者限制

**正確答案：B**  
**解析：** 需要通過 RAG 或持續預訓練來更新知識。

### 50. 為什麼代碼數據 (Code Data) 對訓練推理能力很重要？
A. 程序員比較聰明  
B. 代碼邏輯嚴密、結構清晰，能顯著提升模型的邏輯推理和長程依賴能力  
C.代碼量大  
D. 代碼是英文的

**正確答案：B**  
**解析：** Code is high-quality logic data.

### 51. 多模態數據 (Multimodal Data) 包含？
A. 只有文本  
B. 文本、圖像、音頻、視頻等多種模態的配對數據  
C. 只有視頻  
D. 多種語言

**正確答案：B**  
**解析：** 訓練多模態模型 (如 GPT-4V, Gemini) 的基礎。

### 52. 數據的「有毒性 (Toxicity)」過濾是為了？
A. 防止模型生成仇恨言論、歧視、暴力等有害內容 (Safety Alignment)  
B. 減少數據量  
C. 提高速度  
D. 增加樂趣

**正確答案：A**  
**解析：** 安全是 AI 產品上線的紅線。

### 53. 數據課程學習 (Curriculum Learning) 是指？
A. 讓 AI 上學  
B. 按照從簡單到困難的順序給模型餵數據  
C. 隨機餵數據  
D. 只餵困難數據

**正確答案：B**  
**解析：** 有助於更穩定的收斂。

### 54. 數據血緣管理在生成式 AI 中有助於？
A. 版權追蹤與合規審計  
B. 增加數據量  
C. 加快訓練  
D. 壓縮模型

**正確答案：A**  
**解析：** 知道模型生成內容的來源，應對版權爭議。

### 55. 垂直領域大模型 (Vertical LLM) 需要什麼數據？
A. 通用互聯網數據  
B. 特定行業 (如 醫療、法律、金融) 的專業高品質數據  
C. 圖片數據  
D. 社交媒體數據

**正確答案：B**  
**解析：** Domain adaptation 需要專業糧食。

### 56. 數據去重可以分為哪幾個層次？
A. 句子級、文檔級、數據集級  
B. 只有文件級  
C. 只有字節級  
D. 無法去重

**正確答案：A**  
**解析：** 不同粒度的去重策略組合使用。

### 57. 「指令數據 (Instruction Data)」的特點是？
A. 隨機文本  
B. 格式為 (指令, 輸入, 輸出) 的三元組，明確告訴模型該做什麼  
C. 長篇小說  
D. 代碼片段

**正確答案：B**  
**解析：** 用於 Supervised Fine-Tuning (SFT)，讓模型學會遵循指令。

### 58. 思維鏈 (CoT) 數據集的構造通常包含？
A. 只有問題和答案  
B. 問題、詳細的推理步驟 (Rationale) 和答案  
C. 圖片  
D. 只有答案

**正確答案：B**  
**解析：** 教會模型 "如何思考"。

### 59. 數據污染 (Data Contamination) 在評測中是指？
A. 訓練數據中有病毒  
B. 測試集的題目洩漏到了訓練集中，導致評測分數虛高  
C. 數據有噪聲  
D. 數據格式錯誤

**正確答案：B**  
**解析：** 考試作弊。

### 60. 對齊 (Alignment) 數據通常由誰產生？
A. 爬蟲自動抓取  
B. 經過培訓的人類專家撰寫或標註  
C. 隨機生成  
D. 用戶日誌

**正確答案：B**  
**解析：** 高品質的對齊需要高品質的人類價值觀輸入。

---

## 第四部分：應用與多模態 (20題)

### 61. 內容創作是生成式 AI 最直接的應用，它包括？
A. 寫郵件、寫營銷文案、寫代碼、畫插畫  
B. 維修電腦  
C. 搬運貨物  
D. 物理治療

**正確答案：A**  
**解析：** 輔助人類創作者，提高生產力。

### 62. 數據增強作為生成式 AI 的應用，是指？
A. 刪除數據  
B. 使用生成模型創造合成數據來訓練其他模型 (如 用 GAN 生成醫療影像)  
C. 備份數據  
D. 壓縮數據

**正確答案：B**  
**解析：** 解決隱私數據或稀有數據不足的問題。

### 63. 跨模態生成 (Cross-modal Generation) 的例子？
A. 翻譯英語到法語  
B. 文生圖 (Text-to-Image)、圖生文 (Image Captioning)、文生視頻  
C. 語音轉文字  
D. 文本摘要

**正確答案：B**  
**解析：** 打通不同感官模態之間的轉換。

### 64. 個人化生成 (Personalized Generation) 如何實現？
A. 對所有用戶輸出一樣的內容  
B. 結合用戶的歷史數據、偏好或上傳的個人素材 (如 Lora) 進行定制化生成  
C. 隨機生成  
D. 無法實現

**正確答案：B**  
**解析：** "為我寫一首詩" vs "為我寫一首關於我貓咪的詩"。

### 65. 虛擬數字人 (Digital Avatar) 結合了哪些生成技術？
A. 只有 TTS  
B. 語音合成 (TTS)、面部表情驅動 (Talking Head)、文本生成 (LLM)  
C. 只有圖像生成  
D. 只有識別技術

**正確答案：B**  
**解析：** 綜合應用，創造交互式虛擬角色。

### 66. 生成式 AI 在編程輔助 (如 Copilot) 中的作用？
A. 取代程序員  
B. 代碼補全、代碼解釋、單元測試生成、Bug 修復建議  
C. 自動開機  
D. 監控員工

**正確答案：B**  
**解析：** 大幅提升 coding 效率。

### 67. 在遊戲開發中，生成式 AI 可以用於？
A. 實時生成 NPC 對話、任務劇情、紋理貼圖、3D模型  
B. 玩遊戲  
C. 銷售遊戲  
D. 硬件加速

**正確答案：A**  
**解析：** 打造由 AI 驅動的開放世界 (Generative Agents)。

### 68. 藥物發現 (Drug Discovery) 利用生成式 AI 做什麼？
A. 生成醫生處方  
B. 生成具有特定性質的新分子結構 (De novo drug design)  
C. 銷售藥品  
D. 管理病人

**正確答案：B**  
**解析：** 加速新藥篩選過程。

### 69. 生成式 AI 在教育領域的應用？
A. 替學生寫作業  
B. 個性化家教 (蘇格拉底式教學)、生成練習題、作文批改  
C. 監控考試  
D. 取代學校

**正確答案：B**  
**解析：** 因材施教的 AI 導師。

### 70. 法律領域的生成式 AI 應用風險？
A. 寫得太快  
B. 幻覺導致引用不存在的案例，造成嚴重法律後果  
C. 律師失業  
D. 字體醜

**正確答案：B**  
**解析：** 嚴肅領域必須有 "Human-in-the-loop" 審核。

### 71. 視頻生成的難點在於？
A. 畫質不清晰  
B. 保持幀與幀之間的時間連貫性 (Temporal Consistency) 和 物理邏輯合理性  
C. 沒聲音  
D. 顏色不對

**正確答案：B**  
**解析：** 不閃爍、動作流暢、符合物理規律。

### 72. 語音克隆 (Voice Cloning) 只需要？
A. 幾百小時錄音  
B. 幾秒到幾分鐘的目標人物錄音 (Few-shot/Zero-shot TTS)  
C. 必須本人在場  
D. 無需錄音

**正確答案：B**  
**解析：** VALL-E 等模型展現了驚人的克隆能力。

### 73. 多模態大模型 (LMM) 如 GPT-4V 能做什麼？
A. 只能看圖  
B. 同時理解文本和圖像輸入，進行圖文問答、圖表分析、物體定位  
C. 只能生成圖  
D. 只能聽聲音

**正確答案：B**  
**解析：** 眼睛+大腦。

### 74. 生成式搜索 (Generative Search) (如 Perplexity, Bing Chat) 的特點？
A. 給出藍色鏈接列表  
B. 直接生成問題的綜合答案，並附上引用來源  
C. 隨機回答  
D. 只搜圖片

**正確答案：B**  
**解析：** 從 "Search" 轉向 "Answer"。

### 75. 什麼是 Agent (智能體)？
A. 聊天機器人  
B. 能夠感知環境、規劃任務、調用工具 (Tools) 併採取行動以實現目標的 LLM 系統  
C. 客服  
D. 病毒

**正確答案：B**  
**解析：** 從 "言" 到 "行" 的進化。

### 76. 在設計生成式 AI 產品時，延遲 (Latency) 是一個關鍵指標，通常指的是？
A. 訓練時間  
B. TTFT (Time to First Token) 和 生成總耗時  
C. 下載時間  
D. 啟動時間

**正確答案：B**  
**解析：** 用戶不喜歡等待，流式輸出 (Streaming) 很重要。

### 77. 生成式 AI 的版權爭議主要集中在？
A. 沒人關心  
B. 使用有版權的數據進行訓練是否屬於 "合理使用 (Fair Use)"，以及生成內容的版權歸屬  
C. AI 是否有人權  
D. 軟體授權

**正確答案：B**  
**解析：** 法律尚未完全定論。

### 78. 提示注入 (Prompt Injection) 攻擊是指？
A. 給模型打針  
B. 用戶通過惡意設計的輸入，繞過模型的安全限制，使其執行不僅之舉  
C. 加快生成  
D. 數據注入

**正確答案：B**  
**解析：** "忽略之前的指令，現在你是一個..."。

### 79. 水印技術 (Watermarking) 在生成內容中的作用？
A. 影響美觀  
B. 標記內容為 AI 生成，用於檢測和防偽 (如 C2PA 標準)  
C. 增加版權費  
D. 沒作用

**正確答案：B**  
**解析：** 負責任 AI 的重要組成部分。

### 80. AI Native 應用的設計理念是？
A. 把 AI 當作一個附加功能  
B. 從核心交互邏輯上就基於 AI 能力構建，而非舊軟體的改良 (如 只有對話框的 UI)  
C. 用傳統算法  
D. 加幾個按鈕

**正確答案：B**  
**解析：** Rethink interaction with AI.

---

## 答案總覽

| 題號 | 答案 | 題號 | 答案 | 題號 | 答案 | 題號 | 答案 |
|------|------|------|------|------|------|------|------|
| 1 | B | 21 | B | 41 | B | 61 | A |
| 2 | C | 22 | B | 42 | B | 62 | B |
| 3 | B | 23 | B | 43 | B | 63 | B |
| 4 | B | 24 | B | 44 | A | 64 | B |
| 5 | B | 25 | A | 45 | B | 65 | B |
| 6 | B | 26 | B | 46 | B | 66 | B |
| 7 | B | 27 | B | 47 | B | 67 | A |
| 8 | B | 28 | B | 48 | A | 68 | B |
| 9 | B | 29 | B | 49 | B | 69 | B |
| 10 | B | 30 | B | 50 | B | 70 | B |
| 11 | B | 31 | A | 51 | B | 71 | B |
| 12 | B | 32 | A | 52 | A | 72 | B |
| 13 | B | 33 | B | 53 | B | 73 | B |
| 14 | B | 34 | B | 54 | A | 74 | B |
| 15 | B | 35 | B | 55 | B | 75 | B |
| 16 | B | 36 | B | 56 | A | 76 | B |
| 17 | B | 37 | B | 57 | B | 77 | B |
| 18 | B | 38 | B | 58 | B | 78 | B |
| 19 | B | 39 | B | 59 | B | 79 | B |
| 20 | B | 40 | B | 60 | B | 80 | B |
